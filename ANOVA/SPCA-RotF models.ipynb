{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XaDLqVcOJZwZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.decomposition import PCA,SparsePCA,IncrementalPCA,TruncatedSVD,FastICA,MiniBatchSparsePCA,FactorAnalysis\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from scipy.stats import shapiro,f_oneway,kruskal\n",
        "\n",
        "data = pd.read_csv(\"Electrical Grid.csv\")\n",
        "\n",
        "data_x = data.drop(['stab','stabf'],axis=1)\n",
        "data_y = data['stab']\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaled_x = scaler.fit_transform(data_x)\n",
        "scaled_x = pd.DataFrame(scaled_x, columns=data_x.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tJ_yjZ5xKCG2"
      },
      "outputs": [],
      "source": [
        "depth_data = pd.read_csv(\"depth.csv\")\n",
        "tree_data = pd.read_csv(\"tree.csv\")\n",
        "max_feature_data = pd.read_csv(\"max feature.csv\")\n",
        "bootstrap_size_data = pd.read_csv(\"bootstrap size.csv\")\n",
        "batch_data = pd.read_csv(\"batch size.csv\")\n",
        "iteration_data = pd.read_csv(\"iteration.csv\")\n",
        "\n",
        "best_parameter = pd.read_csv(\"bast parameter.csv\")\n",
        "anova_data = pd.read_csv(\"anova result.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lXmMT6YsJ9Sy"
      },
      "outputs": [],
      "source": [
        "def normal_test(data):\n",
        "    test_stat,p_value = shapiro(data)\n",
        "    return np.round(p_value,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AzDJ1rtbKBj0"
      },
      "outputs": [],
      "source": [
        "spca_rotf_paremater_set = {\"trees\": [100,300, 500, 700], \"sampling_sizes\": [0.5, 0.7, 0.9], 'depths': [10, 20, 30, 40, 50],\n",
        "               'batch': [3, 5, 7, 9], 'iterations ': [100, 300, 500, 700]}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SPCA-RotF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zCD4wA-kNJiy"
      },
      "outputs": [],
      "source": [
        "def get_random_subset(iterable,k):\n",
        "    subsets = []\n",
        "    iteration = 0\n",
        "    np.random.shuffle(iterable)\n",
        "    subset = 0\n",
        "    limit = len(iterable)/k\n",
        "    while iteration < limit:\n",
        "        if k <= len(iterable):\n",
        "            subset = k\n",
        "        else:\n",
        "            subset = len(iterable)\n",
        "        subsets.append(iterable[-subset:])\n",
        "        del iterable[-subset:]\n",
        "        iteration+=1\n",
        "    return subsets\n",
        "\n",
        "def Rotation_Forest_SPCA(X, Y, test_x, max_depth, size, n_trees, k, batch, iter):\n",
        "    r_matrices, models = [], []\n",
        "\n",
        "    for tree in range(n_trees):\n",
        "        feature_index = list(range(X.shape[1]))\n",
        "        # 每個子集有k個特徵，每個子集特徵不重複 #將訓練集中的屬性拆分為大小相等的 K 個非重疊子集。\n",
        "        k_subset = get_random_subset(feature_index, k)\n",
        "        rotation_matrix = np.zeros(\n",
        "            (X.shape[1], X.shape[1]), dtype=float)  # 591*591大小的矩陣\n",
        "\n",
        "        for each_subset in k_subset:\n",
        "            pca = MiniBatchSparsePCA(batch_size=batch, n_iter=iter)\n",
        "            X_train, X_test, y_train, y_test = train_test_split(\n",
        "                X, Y, train_size=size)\n",
        "            X_subset = X_train.iloc[:, each_subset]\n",
        "            pca.fit(X_subset)\n",
        "            for i in range(0, len(pca.components_)):\n",
        "                for j in range(0, len(pca.components_)):\n",
        "                    rotation_matrix[each_subset[i],each_subset[j]] = pca.components_[i, j]\n",
        "        x_transformed = X.dot(rotation_matrix)\n",
        "        model = DecisionTreeRegressor(max_depth=max_depth)\n",
        "        model.fit(x_transformed, Y)\n",
        "        models.append(model)  # 存放每個樹的模型\n",
        "        r_matrices.append(rotation_matrix)  # 存放每個樹的旋轉矩陣\n",
        "\n",
        "    return models, r_matrices\n",
        "\n",
        "def model_predict(models,r_matrices,x):\n",
        "    predicted_ys = []\n",
        "    for i,model in enumerate(models):\n",
        "        x_mod =  x.dot(r_matrices[i])  \n",
        "        predicted_y = model.predict(x_mod)\n",
        "        predicted_ys.append(predicted_y)\n",
        "        \n",
        "    final_results = []\n",
        "    for i in range(len(predicted_ys[0])): #總共要預測的Y有幾個 #2000個預測值\n",
        "        predict_result = [] #存放每棵樹的預測值 #100棵樹有100個預測值\n",
        "        for j in range(len(predicted_ys)): #每棵樹的預測值 #100棵樹\n",
        "            predict_result.append( (predicted_ys[j][i]) )\n",
        "        final_results.append(np.mean(predict_result))\n",
        "\n",
        "    return final_results\n",
        "\n",
        "\n",
        "def SPCA_RotF_kfold(tree, depth, max_sample, batch_size, iteration,seed):\n",
        "    RMSE_set_spca_rotf = []\n",
        "    kf = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "    # split()  method generate indices to split data intSo training and test set.\n",
        "    for train_index, valid_index in kf.split(scaled_x, data_y):\n",
        "        # print('fold',cnt)\n",
        "        train_x = scaled_x.iloc[train_index, :]\n",
        "        train_y = data.iloc[train_index, :]['stab']\n",
        "        valid_x = scaled_x.iloc[valid_index, :]\n",
        "        valid_y = data.iloc[valid_index, :]['stab']\n",
        "\n",
        "        models, r_matrices = Rotation_Forest_SPCA(X=train_x, Y=train_y, test_x=valid_x, max_depth=depth, size=max_sample,\n",
        "                                                  n_trees=tree, k=3, batch=batch_size, iter=iteration)\n",
        "        spca_rot_pred = model_predict(models, r_matrices, valid_x)\n",
        "\n",
        "        RMSE_set_spca_rotf.append(\n",
        "            np.sqrt(mean_squared_error(valid_y, spca_rot_pred)))\n",
        "\n",
        "    mean_rmse = np.mean(RMSE_set_spca_rotf)\n",
        "    return RMSE_set_spca_rotf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================ trees ================\n",
            "100 0.8 [0.011186624345034504, 0.011333951107553706, 0.011055273252098544, 0.01098110576681369, 0.010937378909094006, 0.010607870175775882, 0.01153450973717361, 0.01123460964522041, 0.010710483239176543, 0.010664204132734017]\n",
            "300 0.432 [0.010942888142561101, 0.011027614554259681, 0.010918216055917513, 0.0107857859202755, 0.010927071421154868, 0.010383603507246831, 0.011252670571592412, 0.011158081630928525, 0.010797298576736803, 0.010806760365062841]\n",
            "500 0.293 [0.010974117765023661, 0.011044447325856657, 0.010913377699527202, 0.010787671341349574, 0.010871551664656982, 0.01032419892841868, 0.011175038666316198, 0.010892385778770882, 0.010718452405726593, 0.010782441566491881]\n",
            "700 0.385 [0.010966610259141746, 0.011080569085347788, 0.010940861438984126, 0.010773119223858504, 0.010844072599316449, 0.010285777368028246, 0.011211361832527014, 0.0110754798170548, 0.010696167786797672, 0.010798684586321817]\n",
            "f_oneway: 0.935390133992195 0.43363375923352454\n",
            "================ sampling_sizes ================\n",
            "0.5 0.068 [0.010933867808041486, 0.011009377693938354, 0.011026847231961009, 0.01076311397712674, 0.010823436348301982, 0.01032538742820077, 0.011092642681541098, 0.011054016021827399, 0.010727473047556453, 0.010887536764105935]\n",
            "0.7 0.127 [0.011225253984843815, 0.011183102474273883, 0.01106637562296106, 0.010929618090345043, 0.011021180289396438, 0.010463964584603134, 0.011363653945991392, 0.011088927146972918, 0.011010637705263433, 0.010966618299793457]\n",
            "0.9 0.992 [0.011110124215532268, 0.011202089563167941, 0.011315694727777813, 0.011065308160172387, 0.01143617037942271, 0.01067251816761913, 0.01160448874573628, 0.011380078927733796, 0.01094297541483391, 0.010830568255520378]\n",
            "f_oneway: 3.3478826608290646 0.0502509100284169\n",
            "================ depths ================\n",
            "10 0.757 [0.012423559592484578, 0.012304579101925896, 0.01217743291641235, 0.012099607493736798, 0.012176000474246771, 0.011589384583629797, 0.012617450072749746, 0.01236394301214899, 0.01213914854153396, 0.011888081881247526]\n",
            "20 0.309 [0.011354635705439417, 0.0112042990078051, 0.01095410365887959, 0.010908311949535142, 0.011192437040048213, 0.010445132139842982, 0.011280568024770225, 0.01127613058092059, 0.010745961547551685, 0.010761879406164947]\n",
            "30 0.159 [0.010991396945695063, 0.011226182860938867, 0.01102013991815367, 0.010976695124461639, 0.010976911816653553, 0.010408419054054058, 0.011283126869422073, 0.011314384197153401, 0.010904635460007701, 0.010846745190688518]\n",
            "40 0.81 [0.011265634518256726, 0.01112905913484967, 0.011010677600062696, 0.01066545064395321, 0.010974466590888946, 0.010648295804156448, 0.011408175159632893, 0.011203900710676472, 0.010959053808815874, 0.01080446170314708]\n",
            "50 0.81 [0.011230479264063195, 0.011053118002832322, 0.01099789473440708, 0.0111516587784498, 0.010802142835545394, 0.010484548932541611, 0.011337061011711991, 0.01112531169991942, 0.010879640203645144, 0.010851594811004154]\n",
            "F_onewayResult(statistic=38.06421517336322, pvalue=6.654255680247559e-14)\n",
            "================ batch ================\n",
            "3 0.468 [0.011195339878250303, 0.011402846387574985, 0.011085493767909748, 0.010734048427982725, 0.011203845149700475, 0.01066534117303401, 0.011339418627782077, 0.01125728106459973, 0.010889165125795021, 0.010885614708159106]\n",
            "5 0.848 [0.011341730202853713, 0.011014829315328758, 0.011099281867443443, 0.011029806444617965, 0.010915247013980778, 0.010516582926244756, 0.011318290119252856, 0.011123939364161322, 0.010844521855137838, 0.01076890019829186]\n",
            "7 0.577 [0.01106755998492324, 0.011343366979244452, 0.011151224740602896, 0.010977768424275126, 0.011143772389514021, 0.010604730470600536, 0.011327147835067834, 0.011280865486264875, 0.01077545879836051, 0.010921026892089505]\n",
            "9 0.852 [0.011091664476393379, 0.011265959579152354, 0.011086204625359425, 0.011083197472329123, 0.011170938465057302, 0.010587632630883033, 0.011394735917353077, 0.01146154242234654, 0.010904747034949355, 0.010823128503854848]\n",
            "f_oneway: 0.23112119242349974 0.8741008088598965\n",
            "================ iterations  ================\n",
            "[0.01102460103106749, 0.010899999074573608, 0.010848368314213831, 0.010867270399737816]\n",
            "[0.010864369900260122, 0.011031933214444458, 0.011156001655751662]\n",
            "[0.012177918767011641, 0.011012345906095788, 0.010994863743722851, 0.011006917567444003, 0.010991345027412011]\n",
            "[0.011065839431078818, 0.01099731293073133, 0.011059292200094299, 0.011086975112767844]\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'iter_result' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 181\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[39mprint\u001b[39m(depth_result)\n\u001b[0;32m    180\u001b[0m \u001b[39mprint\u001b[39m(batch_result)\n\u001b[1;32m--> 181\u001b[0m \u001b[39mprint\u001b[39m(iter_result)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'iter_result' is not defined"
          ]
        }
      ],
      "source": [
        "num = 2\n",
        "\n",
        "for param_name, parameter in spca_rotf_paremater_set.items():\n",
        "    print('================',param_name,'================')\n",
        "    if param_name == 'trees':\n",
        "        tree_rmse  = []\n",
        "        best_rmse,best_para = 100,1000\n",
        "        min_normality_p = 100\n",
        "        for para in parameter:\n",
        "            parm_set_2 = SPCA_RotF_kfold(tree=para, depth=30, max_sample=0.7, batch_size=5, iteration=100,seed = 47 ) #23 31 47 52\n",
        "            print(para,normal_test(parm_set_2),parm_set_2)\n",
        "\n",
        "            # 找出最好的樹參數\n",
        "            if np.mean(parm_set_2) < best_rmse:\n",
        "              best_tree = para\n",
        "              best_rmse = np.mean(parm_set_2)\n",
        "            tree_rmse.append(parm_set_2)\n",
        "            \n",
        "            # 紀錄每個參數的常態檢定p-value\n",
        "            tree_data[str(para)].iloc[num] = normal_test(parm_set_2)\n",
        "\n",
        "            if normal_test(parm_set_2) < min_normality_p:\n",
        "              min_normality_p = normal_test(parm_set_2)\n",
        "\n",
        "        if min_normality_p < 0.05 :\n",
        "          test_stat,anova_p = kruskal(tree_rmse[0],tree_rmse[1],tree_rmse[2],tree_rmse[3])\n",
        "          print('kruskal_oneway:',test_stat,anova_p)              \n",
        "        else:\n",
        "          test_stat,anova_p = f_oneway(tree_rmse[0],tree_rmse[1],tree_rmse[2],tree_rmse[3])\n",
        "          print('f_oneway:',test_stat,anova_p)\n",
        "\n",
        "        anova_data['trees'].iloc[num] = np.round(anova_p,3)    # 紀錄該參數的anova result\n",
        "        best_parameter['trees'].iloc[num] = best_tree   # 紀錄該參數的最佳參數\n",
        "        tree_result = [np.mean(tree_rmse[0]),np.mean(tree_rmse[1]),np.mean(tree_rmse[2]),np.mean(tree_rmse[3])]   # 紀錄每個參數之平均rmse\n",
        "\n",
        "########################################################################################################################################\n",
        "\n",
        "    elif param_name == 'sampling_sizes':\n",
        "        sample_rmse = []\n",
        "        best_rmse,best_para = 100,1000\n",
        "        min_normality_p = 100\n",
        "        for para in parameter:\n",
        "            parm_set_2 = SPCA_RotF_kfold(tree=100, depth=30, max_sample=para, batch_size=5, iteration=100,seed = 47 )\n",
        "            print(para,normal_test(parm_set_2),parm_set_2)\n",
        "\n",
        "            # 找出最好的參數\n",
        "            if np.mean(parm_set_2) < best_rmse:\n",
        "              best_para = para\n",
        "              best_rmse = np.mean(parm_set_2)\n",
        "            sample_rmse.append(parm_set_2)\n",
        "\n",
        "            # 紀錄每個參數的常態檢定p-value\n",
        "            bootstrap_size_data[str(para)].iloc[num] = normal_test(parm_set_2)\n",
        "\n",
        "            if normal_test(parm_set_2) < min_normality_p:\n",
        "              min_normality_p = normal_test(parm_set_2)\n",
        "              \n",
        "        if min_normality_p < 0.05 :\n",
        "          test_stat,anova_p = kruskal(sample_rmse[0],sample_rmse[1],sample_rmse[2])\n",
        "          print('kruskal_oneway:',test_stat,anova_p)              \n",
        "        else:\n",
        "          test_stat,anova_p = f_oneway(sample_rmse[0],sample_rmse[1],sample_rmse[2])\n",
        "          print('f_oneway:',test_stat,anova_p)\n",
        "\n",
        "        anova_data['bootstrap size'].iloc[num] = np.round(anova_p,3)\n",
        "\n",
        "        best_parameter['bootstrap size'].iloc[num] = best_para   # 紀錄該參數的最佳參數\n",
        "        bootstrap_result = [np.mean(sample_rmse[0]),np.mean(sample_rmse[1]),np.mean(sample_rmse[2])]  # 紀錄每個參數之平均rmse\n",
        "\n",
        "########################################################################################################################################\n",
        "\n",
        "    elif param_name == 'depths':\n",
        "        depth_rmse = []\n",
        "        best_rmse,best_para = 100,1000\n",
        "        for para in parameter:\n",
        "            parm_set_2 = SPCA_RotF_kfold(tree=100, depth=para, max_sample=0.7, batch_size=5, iteration=100,seed = 47)\n",
        "            print(para,normal_test(parm_set_2),parm_set_2)\n",
        "\n",
        "            # 找出最好的參數\n",
        "            if np.mean(parm_set_2) < best_rmse:\n",
        "              best_para = para\n",
        "              best_rmse = np.mean(parm_set_2)\n",
        "            depth_rmse.append(parm_set_2)\n",
        "\n",
        "            # 紀錄每個參數的常態檢定p-value\n",
        "            depth_data[str(para)].iloc[num] = normal_test(parm_set_2)\n",
        "\n",
        "        print(f_oneway(depth_rmse[0],depth_rmse[1],depth_rmse[2],depth_rmse[3],depth_rmse[4]))\n",
        "\n",
        "        # 紀錄該參數的anova result\n",
        "        test_stat,anova_p = f_oneway(depth_rmse[0],depth_rmse[1],depth_rmse[2],depth_rmse[3],depth_rmse[4])\n",
        "        anova_data['max depth'].iloc[num] = np.round(anova_p,3)\n",
        "\n",
        "        # 紀錄該參數的最佳參數\n",
        "        best_parameter['max depth'].iloc[num] = best_para\n",
        "\n",
        "        # 紀錄每個參數之平均rmse\n",
        "        depth_result = [np.mean(depth_rmse[0]),np.mean(depth_rmse[1]),np.mean(depth_rmse[2]),np.mean(depth_rmse[3]),np.mean(depth_rmse[4])]\n",
        "\n",
        "########################################################################################################################################\n",
        "\n",
        "    elif param_name == 'batch':\n",
        "        batch_rmse = []\n",
        "        best_rmse,best_para = 100,1000\n",
        "        min_normality_p = 100\n",
        "\n",
        "        for para in parameter:\n",
        "            parm_set_2 = SPCA_RotF_kfold(tree=100, depth=30, max_sample=0.7, batch_size=para, iteration=100,seed = 42)\n",
        "            print(para,normal_test(parm_set_2),parm_set_2)\n",
        "\n",
        "            # 找出最好的參數\n",
        "            if np.mean(parm_set_2) < best_rmse:\n",
        "              best_para = para\n",
        "              best_rmse = np.mean(parm_set_2)\n",
        "            batch_rmse.append(parm_set_2)\n",
        "\n",
        "            # 紀錄每個參數的常態檢定p-value\n",
        "            batch_data[str(para)].iloc[num] = normal_test(parm_set_2)\n",
        "\n",
        "            if normal_test(parm_set_2) < min_normality_p:\n",
        "              min_normality_p = normal_test(parm_set_2)\n",
        "              \n",
        "        if min_normality_p < 0.05 :\n",
        "          test_stat,anova_p = kruskal(batch_rmse[0],batch_rmse[1],batch_rmse[2],batch_rmse[3])\n",
        "          print('kruskal_oneway:',test_stat,anova_p)              \n",
        "        else:\n",
        "          test_stat,anova_p = f_oneway(batch_rmse[0],batch_rmse[1],batch_rmse[2],batch_rmse[3])\n",
        "          print('f_oneway:',test_stat,anova_p)\n",
        "\n",
        "        # 紀錄該參數的anova result\n",
        "        anova_data['batch size'].iloc[num] = np.round(anova_p,3)\n",
        "\n",
        "        # 紀錄該參數的最佳參數\n",
        "        best_parameter['batch size'].iloc[num] = best_para\n",
        "\n",
        "        # 紀錄每個參數之平均rmse\n",
        "        batch_result = [np.mean(batch_rmse[0]),np.mean(batch_rmse[1]),np.mean(batch_rmse[2]),np.mean(batch_rmse[3])]\n",
        "\n",
        "########################################################################################################################################\n",
        "\n",
        "    elif param_name == 'iterations':\n",
        "        iter_rmse = []\n",
        "        best_rmse,best_para = 100,1000\n",
        "        min_normality_p = 1000\n",
        "        for para in parameter:\n",
        "            parm_set_2 = SPCA_RotF_kfold(tree=100, depth=30, max_sample=0.7, batch_size=5, iteration=para ,seed = 47)\n",
        "            print(para,normal_test(parm_set_2),parm_set_2)\n",
        "\n",
        "            # 找出最好的參數\n",
        "            if np.mean(parm_set_2) < best_rmse:\n",
        "              best_para = para\n",
        "              best_rmse = np.mean(parm_set_2)\n",
        "            iter_rmse.append(parm_set_2)\n",
        "\n",
        "            # 紀錄每個參數的常態檢定p-value\n",
        "            iteration_data[str(para)].iloc[num] = normal_test(parm_set_2)\n",
        "\n",
        "            if normal_test(parm_set_2) < min_normality_p:\n",
        "              min_normality_p = normal_test(parm_set_2)\n",
        "              \n",
        "        if min_normality_p < 0.05 :\n",
        "          test_stat,anova_p = kruskal(iter_rmse[0],iter_rmse[1],iter_rmse[2],iter_rmse[3])\n",
        "          print('kruskal_oneway:',test_stat,anova_p)              \n",
        "        else:\n",
        "          test_stat,anova_p = f_oneway(iter_rmse[0],iter_rmse[1],iter_rmse[2],iter_rmse[3])\n",
        "          print('f_oneway:',test_stat,anova_p)\n",
        "  \n",
        "        # 紀錄該參數的anova result\n",
        "        anova_data['iteration'].iloc[num] = np.round(anova_p,3)\n",
        "\n",
        "        # 紀錄該參數的最佳參數\n",
        "        best_parameter['iteration'].iloc[num] = best_para\n",
        "\n",
        "        # 紀錄每個參數之平均rmse\n",
        "        iter_result = [np.mean(iter_rmse[0]),np.mean(iter_rmse[1]),np.mean(iter_rmse[2]),np.mean(iter_rmse[3])]\n",
        "\n",
        "print(tree_result)\n",
        "print(bootstrap_result)\n",
        "print(depth_result)\n",
        "print(batch_result)\n",
        "print(iter_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================ iteration ================\n",
            "100 0.69 [0.011147885303628077, 0.011372689537538914, 0.011303127557971344, 0.011192143219290802, 0.011200087303894334, 0.010684656142861269, 0.011499547612180697, 0.011274659132133446, 0.010987677973412432, 0.011053465881325483]\n",
            "300 0.408 [0.011216239910345078, 0.011251427307664244, 0.01094052784430253, 0.010732109475539563, 0.010978267981822599, 0.01054604320034549, 0.011245480294138823, 0.011134253418070983, 0.010887467654550191, 0.010688824050071497]\n",
            "500 0.681 [0.011084742461422532, 0.011287303132342911, 0.010885884865883629, 0.010785051443319994, 0.011042375075701027, 0.010532010446870322, 0.011281829428372867, 0.01106950498775395, 0.010760789836102893, 0.010675496515466211]\n",
            "700 0.094 [0.01097544938079634, 0.010980191382207545, 0.01097553939325251, 0.010801627826532847, 0.010832794056824295, 0.010262797084308203, 0.011239652308964426, 0.011017296379323317, 0.01074208580475375, 0.010842301790285462]\n",
            "f_oneway: 2.8039578992550367 0.05355024415864722\n",
            "[0.011171593966423681, 0.0109620641136851, 0.010940498819323633, 0.01086697354072487]\n"
          ]
        }
      ],
      "source": [
        "num = 2\n",
        "for param_name, parameter in spca_rotf_paremater_set.items():\n",
        "    if param_name == 'iterations ':\n",
        "        print('================ iteration ================')\n",
        "        iter_rmse = []\n",
        "        best_rmse,best_para = 100,1000\n",
        "        min_normality_p = 1000\n",
        "        for para in parameter:\n",
        "            parm_set_2 = SPCA_RotF_kfold(tree=100, depth=30, max_sample=0.9, batch_size=5, iteration=para ,seed = 47)\n",
        "            print(para,normal_test(parm_set_2),parm_set_2)\n",
        "\n",
        "            # 找出最好的參數\n",
        "            if np.mean(parm_set_2) < best_rmse:\n",
        "              best_para = para\n",
        "              best_rmse = np.mean(parm_set_2)\n",
        "            iter_rmse.append(parm_set_2)\n",
        "\n",
        "            # 紀錄每個參數的常態檢定p-value\n",
        "            iteration_data[str(para)].iloc[num] = normal_test(parm_set_2)\n",
        "\n",
        "            if normal_test(parm_set_2) < min_normality_p:\n",
        "              min_normality_p = normal_test(parm_set_2)\n",
        "              \n",
        "        if min_normality_p < 0.05 :\n",
        "          test_stat,anova_p = kruskal(iter_rmse[0],iter_rmse[1],iter_rmse[2],iter_rmse[3])\n",
        "          print('kruskal_oneway:',test_stat,anova_p)              \n",
        "        else:\n",
        "          test_stat,anova_p = f_oneway(iter_rmse[0],iter_rmse[1],iter_rmse[2],iter_rmse[3])\n",
        "          print('f_oneway:',test_stat,anova_p)\n",
        "  \n",
        "        # 紀錄該參數的anova result\n",
        "        anova_data['iteration'].iloc[num] = np.round(anova_p,3)\n",
        "\n",
        "        # 紀錄該參數的最佳參數\n",
        "        best_parameter['iteration'].iloc[num] = best_para\n",
        "\n",
        "        # 紀錄每個參數之平均rmse\n",
        "        iter_result = [np.mean(iter_rmse[0]),np.mean(iter_rmse[1]),np.mean(iter_rmse[2]),np.mean(iter_rmse[3])]\n",
        "\n",
        "print(iter_result)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SPCA-TWRotF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def weighted_average(prediction_set,oobrmse):\n",
        "    final_results = []\n",
        "    for i in range(len(prediction_set[0])): #總共要預測的Y有幾個 #2000個預測值\n",
        "        predict_result = [] #存放每棵樹的預測值 #100棵樹有100個預測值\n",
        "        final_result = 0\n",
        "        for j in range(len(prediction_set)): #每棵樹的預測值 #100棵樹\n",
        "            predict_result.append( (prediction_set[j][i]) )\n",
        "\n",
        "        for k in range(len(predict_result)): #加權預測值\n",
        "            final_result =  final_result + predict_result[k] * oobrmse[k]\n",
        "        final_results.append(final_result)\n",
        "    return final_results\n",
        "\n",
        "def Tree_Weighting_Rotation_Forest_SPCA(X , Y, test_x, max_depth, size, n_trees, k, batch, iter):\n",
        "    strength_set = []\n",
        "    Prediction_set = []\n",
        "    OOB_MSE = []\n",
        "    r_matrices , models = [],[]\n",
        "    for tree in range(n_trees):\n",
        "        feature_index = list(range(X.shape[1]))\n",
        "        k_subset = get_random_subset(feature_index,k) #每個子集有k個特徵，每個子集特徵不重複 #將訓練集中的屬性拆分為大小相等的 K 個非重疊子集。\n",
        "        rotation_matrix = np.zeros((X.shape[1],X.shape[1]),dtype=float) #591*591大小的矩陣\n",
        "        X_train, X_valid, y_train, y_valid = train_test_split(X, Y, train_size = size)\n",
        "\n",
        "        for each_subset in k_subset:\n",
        "            pca = MiniBatchSparsePCA(batch_size = batch ,n_iter = iter )\n",
        "            x_train,_,_,_ = train_test_split(X_train, y_train, train_size = 0.7)\n",
        "            X_subset = x_train.iloc[:,each_subset]\n",
        "            pca.fit(X_subset)\n",
        "            for i in range(0,len(pca.components_)):\n",
        "                for j in range(0,len(pca.components_)):\n",
        "                    rotation_matrix[ each_subset[i],each_subset[j] ] = pca.components_[i,j]\n",
        "\n",
        "        x_transformed = X_train.dot(rotation_matrix)\n",
        "        model = DecisionTreeRegressor(max_depth = max_depth).fit(x_transformed,y_train)\n",
        "\n",
        "        x_valid_transformed = X_valid.dot(rotation_matrix)\n",
        "        valid_prediction = model.predict(x_valid_transformed)\n",
        "\n",
        "        models.append(model) #存放每個樹的模型\n",
        "        r_matrices.append(rotation_matrix) #存放每個樹的旋轉矩陣\n",
        "\n",
        "        OOB_MSE.append(mean_squared_error(y_valid,valid_prediction) )\n",
        "        \n",
        "    oob_mse_prop = OOB_MSE/np.sum(OOB_MSE)\n",
        "    \n",
        "    predicted_ys = [] #測試階段預測\n",
        "    for i,model in enumerate(models): \n",
        "        x_mod =  test_x.dot(r_matrices[i])  \n",
        "        predicted_y = model.predict(x_mod)\n",
        "        predicted_ys.append(predicted_y)\n",
        "\n",
        "    weighted_result = weighted_average(predicted_ys,oob_mse_prop)\n",
        "    return weighted_result\n",
        "\n",
        "def SPCA_TWRotF_kfold(tree, depth, max_sample, batch_size, iteration,seed):\n",
        "    RMSE_set_spca_twrotf = []\n",
        "    kf = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "    # split()  method generate indices to split data intSo training and test set.\n",
        "    for train_index, valid_index in kf.split(scaled_x, data_y):\n",
        "        # print('fold',cnt)\n",
        "        train_x = scaled_x.iloc[train_index, :]\n",
        "        train_y = data.iloc[train_index, :]['stab']\n",
        "        valid_x = scaled_x.iloc[valid_index, :]\n",
        "        valid_y = data.iloc[valid_index, :]['stab']\n",
        "\n",
        "        TWRotF_pred = Tree_Weighting_Rotation_Forest_SPCA(X=train_x, Y=train_y, test_x=valid_x, max_depth=depth, size=max_sample,\n",
        "                                                  n_trees=tree, k=3, batch=batch_size, iter=iteration)\n",
        "        RMSE_set_spca_twrotf.append(np.sqrt(mean_squared_error(valid_y, TWRotF_pred)))\n",
        "\n",
        "    mean_rmse = np.mean(RMSE_set_spca_twrotf)\n",
        "    return RMSE_set_spca_twrotf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================ trees ================\n",
            "100 0.456 [0.011524498632911533, 0.01159982630192036, 0.011359330294501906, 0.011212503301501335, 0.011362260171584381, 0.010942910351022754, 0.011653697857300355, 0.011653980082687409, 0.011198331667814466, 0.011160404610067084]\n",
            "300 0.446 [0.01139551290419669, 0.011356265881226497, 0.011251592480656446, 0.011078512408413115, 0.011255621268979575, 0.010610614421725548, 0.011600346540866072, 0.011342124128683661, 0.01103074069285751, 0.011087178627304404]\n",
            "500 0.439 [0.011318791375520608, 0.011341681323907126, 0.011260701737233295, 0.011007948196829645, 0.0111497671736165, 0.01062556049330323, 0.011464677967662087, 0.011378893632326588, 0.01093169321143305, 0.011121635448351654]\n",
            "700 0.779 [0.011329723106512347, 0.011392392663371302, 0.011237320966428769, 0.011090308970904142, 0.011176903612764815, 0.010721828551404293, 0.011492540291236891, 0.01135539271182622, 0.010991411273634453, 0.010982856061300795]\n",
            "f_oneway: 1.460096242197034 0.2416821935386128\n",
            "================ sampling_sizes ================\n",
            "0.5 0.364 [0.011788895581498754, 0.011780192734701305, 0.011629292858168551, 0.01158217554006795, 0.011536142393947513, 0.01123395004546678, 0.011829780607915228, 0.011881301966538223, 0.011270097089427729, 0.011497290707212816]\n",
            "0.7 0.898 [0.011437747208295266, 0.01139434778076268, 0.01134284398726953, 0.011047672302661887, 0.011342859407974535, 0.01095226757553275, 0.011600758583258, 0.011516273901995432, 0.011158993868418962, 0.011204144309591558]\n",
            "0.9 0.342 [0.011457405737955022, 0.011195148482115943, 0.011342627453648684, 0.011035809903434573, 0.011193994999151434, 0.010706813858632678, 0.011429965476846736, 0.01135063139894538, 0.011113247781967577, 0.011098357453405002]\n",
            "f_oneway: 9.480460298936793 0.0007606118885726371\n",
            "================ depths ================\n",
            "10 0.938 [0.012530089032870926, 0.01218158025832077, 0.012318323323933856, 0.012229550317840308, 0.012373169111566416, 0.011896296224504464, 0.012597311181515594, 0.012336214807676877, 0.012283691358157713, 0.012092809195912256]\n",
            "20 0.228 [0.011572207055422175, 0.011588034476695633, 0.011292763169762384, 0.011253458894266563, 0.011265985263248561, 0.010753585482301905, 0.011553753603930359, 0.011646059207505083, 0.01116478131242329, 0.011145721060808191]\n",
            "30 0.69 [0.011524657856579228, 0.01145828022955642, 0.011328930123951024, 0.011368931064336464, 0.011218719145676697, 0.010891306265773575, 0.011718040123379838, 0.011460520623700558, 0.011307348092244712, 0.011256332917412442]\n",
            "40 0.99 [0.011460317823613331, 0.011454486945399996, 0.011512904568532522, 0.011272195498101541, 0.011190092862756192, 0.010831665960955231, 0.011337862154530077, 0.01170514649517976, 0.01101260598585285, 0.011098269284702075]\n",
            "50 0.544 [0.011404373230254344, 0.011609527694978418, 0.011462679459011558, 0.011373734291257896, 0.011427198496252533, 0.010917643322827608, 0.011709223110166953, 0.011604811502351308, 0.011261390166184776, 0.011247598648214167]\n",
            "F_onewayResult(statistic=31.578901729827223, pvalue=1.5209429506143824e-12)\n",
            "================ batch ================\n",
            "3 0.251 [0.011473338811866983, 0.0116766853594576, 0.011439367905439873, 0.011204442909938382, 0.011439109049581004, 0.010789032501157958, 0.011584113779783176, 0.011391218104950312, 0.011262571692346708, 0.01127510746079087]\n",
            "5 0.491 [0.011606539117968826, 0.011635163620123479, 0.011462755218260217, 0.011155003318921582, 0.011256562242946671, 0.010935164780846232, 0.011582936727135796, 0.011202237054960894, 0.01133709842725193, 0.010995279626395698]\n",
            "7 0.131 [0.011421411818416619, 0.011559335303178337, 0.011379657670924487, 0.011116651753952463, 0.01139511111862594, 0.010663091733109713, 0.011668134829081703, 0.011441109426777429, 0.011381456215518952, 0.011068911731780972]\n",
            "9 0.141 [0.01148187434596737, 0.011476291529154366, 0.01122942189835862, 0.011231798214629735, 0.011285486908105049, 0.010642031173778026, 0.011881245124603194, 0.011445294425623843, 0.011335993533629015, 0.011237015309956185]\n",
            "f_oneway: 0.04897263736285366 0.9854218630474794\n",
            "================ iterations  ================\n",
            "[0.011366774327131157, 0.01120085093549095, 0.011160135056018377, 0.011177067820938403]\n",
            "[0.011602911952494485, 0.011299790892576062, 0.011192400254610302]\n",
            "[0.012283903481229918, 0.011323634952636413, 0.011353306644261095, 0.011287554757962358, 0.011401817992149958]\n",
            "[0.011353498757531288, 0.011316874013481132, 0.011309487160136663, 0.01132464524638054]\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'iter_result' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 181\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[39mprint\u001b[39m(depth_result)\n\u001b[0;32m    180\u001b[0m \u001b[39mprint\u001b[39m(batch_result)\n\u001b[1;32m--> 181\u001b[0m \u001b[39mprint\u001b[39m(iter_result)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'iter_result' is not defined"
          ]
        }
      ],
      "source": [
        "num = 8\n",
        "\n",
        "for param_name, parameter in spca_rotf_paremater_set.items():\n",
        "    print('================',param_name,'================')\n",
        "    if param_name == 'trees':\n",
        "        tree_rmse  = []\n",
        "        best_rmse,best_para = 100,1000\n",
        "        min_normality_p = 100\n",
        "        for para in parameter:\n",
        "            parm_set_2 = SPCA_TWRotF_kfold(tree=para, depth=30, max_sample=0.7, batch_size=5, iteration=100,seed = 47 ) #23 31 47 52\n",
        "            print(para,normal_test(parm_set_2),parm_set_2)\n",
        "\n",
        "            # 找出最好的樹參數\n",
        "            if np.mean(parm_set_2) < best_rmse:\n",
        "              best_tree = para\n",
        "              best_rmse = np.mean(parm_set_2)\n",
        "            tree_rmse.append(parm_set_2)\n",
        "            \n",
        "            # 紀錄每個參數的常態檢定p-value\n",
        "            tree_data[str(para)].iloc[num] = normal_test(parm_set_2)\n",
        "\n",
        "            if normal_test(parm_set_2) < min_normality_p:\n",
        "              min_normality_p = normal_test(parm_set_2)\n",
        "\n",
        "        if min_normality_p < 0.05 :\n",
        "          test_stat,anova_p = kruskal(tree_rmse[0],tree_rmse[1],tree_rmse[2],tree_rmse[3])\n",
        "          print('kruskal_oneway:',test_stat,anova_p)              \n",
        "        else:\n",
        "          test_stat,anova_p = f_oneway(tree_rmse[0],tree_rmse[1],tree_rmse[2],tree_rmse[3])\n",
        "          print('f_oneway:',test_stat,anova_p)\n",
        "\n",
        "        anova_data['trees'].iloc[num] = np.round(anova_p,3)    # 紀錄該參數的anova result\n",
        "        best_parameter['trees'].iloc[num] = best_tree   # 紀錄該參數的最佳參數\n",
        "        tree_result = [np.mean(tree_rmse[0]),np.mean(tree_rmse[1]),np.mean(tree_rmse[2]),np.mean(tree_rmse[3])]   # 紀錄每個參數之平均rmse\n",
        "\n",
        "########################################################################################################################################\n",
        "\n",
        "    elif param_name == 'sampling_sizes':\n",
        "        sample_rmse = []\n",
        "        best_rmse,best_para = 100,1000\n",
        "        min_normality_p = 100\n",
        "        for para in parameter:\n",
        "            parm_set_2 = SPCA_TWRotF_kfold(tree=100, depth=30, max_sample=para, batch_size=5, iteration=100,seed = 47 )\n",
        "            print(para,normal_test(parm_set_2),parm_set_2)\n",
        "\n",
        "            # 找出最好的參數\n",
        "            if np.mean(parm_set_2) < best_rmse:\n",
        "              best_para = para\n",
        "              best_rmse = np.mean(parm_set_2)\n",
        "            sample_rmse.append(parm_set_2)\n",
        "\n",
        "            # 紀錄每個參數的常態檢定p-value\n",
        "            bootstrap_size_data[str(para)].iloc[num] = normal_test(parm_set_2)\n",
        "\n",
        "            if normal_test(parm_set_2) < min_normality_p:\n",
        "              min_normality_p = normal_test(parm_set_2)\n",
        "              \n",
        "        if min_normality_p < 0.05 :\n",
        "          test_stat,anova_p = kruskal(sample_rmse[0],sample_rmse[1],sample_rmse[2])\n",
        "          print('kruskal_oneway:',test_stat,anova_p)              \n",
        "        else:\n",
        "          test_stat,anova_p = f_oneway(sample_rmse[0],sample_rmse[1],sample_rmse[2])\n",
        "          print('f_oneway:',test_stat,anova_p)\n",
        "\n",
        "        anova_data['bootstrap size'].iloc[num] = np.round(anova_p,3)\n",
        "\n",
        "        best_parameter['bootstrap size'].iloc[num] = best_para   # 紀錄該參數的最佳參數\n",
        "        bootstrap_result = [np.mean(sample_rmse[0]),np.mean(sample_rmse[1]),np.mean(sample_rmse[2])]  # 紀錄每個參數之平均rmse\n",
        "\n",
        "########################################################################################################################################\n",
        "\n",
        "    elif param_name == 'depths':\n",
        "        depth_rmse = []\n",
        "        best_rmse,best_para = 100,1000\n",
        "        for para in parameter:\n",
        "            parm_set_2 = SPCA_TWRotF_kfold(tree=100, depth=para, max_sample=0.7, batch_size=5, iteration=100,seed = 47)\n",
        "            print(para,normal_test(parm_set_2),parm_set_2)\n",
        "\n",
        "            # 找出最好的參數\n",
        "            if np.mean(parm_set_2) < best_rmse:\n",
        "              best_para = para\n",
        "              best_rmse = np.mean(parm_set_2)\n",
        "            depth_rmse.append(parm_set_2)\n",
        "\n",
        "            # 紀錄每個參數的常態檢定p-value\n",
        "            depth_data[str(para)].iloc[num] = normal_test(parm_set_2)\n",
        "\n",
        "        print(f_oneway(depth_rmse[0],depth_rmse[1],depth_rmse[2],depth_rmse[3],depth_rmse[4]))\n",
        "\n",
        "        # 紀錄該參數的anova result\n",
        "        test_stat,anova_p = f_oneway(depth_rmse[0],depth_rmse[1],depth_rmse[2],depth_rmse[3],depth_rmse[4])\n",
        "        anova_data['max depth'].iloc[num] = np.round(anova_p,3)\n",
        "\n",
        "        # 紀錄該參數的最佳參數\n",
        "        best_parameter['max depth'].iloc[num] = best_para\n",
        "\n",
        "        # 紀錄每個參數之平均rmse\n",
        "        depth_result = [np.mean(depth_rmse[0]),np.mean(depth_rmse[1]),np.mean(depth_rmse[2]),np.mean(depth_rmse[3]),np.mean(depth_rmse[4])]\n",
        "\n",
        "########################################################################################################################################\n",
        "\n",
        "    elif param_name == 'batch':\n",
        "        batch_rmse = []\n",
        "        best_rmse,best_para = 100,1000\n",
        "        min_normality_p = 100\n",
        "\n",
        "        for para in parameter:\n",
        "            parm_set_2 = SPCA_TWRotF_kfold(tree=100, depth=30, max_sample=0.7, batch_size=para, iteration=100,seed = 47)\n",
        "            print(para,normal_test(parm_set_2),parm_set_2)\n",
        "\n",
        "            # 找出最好的參數\n",
        "            if np.mean(parm_set_2) < best_rmse:\n",
        "              best_para = para\n",
        "              best_rmse = np.mean(parm_set_2)\n",
        "            batch_rmse.append(parm_set_2)\n",
        "\n",
        "            # 紀錄每個參數的常態檢定p-value\n",
        "            batch_data[str(para)].iloc[num] = normal_test(parm_set_2)\n",
        "\n",
        "            if normal_test(parm_set_2) < min_normality_p:\n",
        "              min_normality_p = normal_test(parm_set_2)\n",
        "              \n",
        "        if min_normality_p < 0.05 :\n",
        "          test_stat,anova_p = kruskal(batch_rmse[0],batch_rmse[1],batch_rmse[2],batch_rmse[3])\n",
        "          print('kruskal_oneway:',test_stat,anova_p)              \n",
        "        else:\n",
        "          test_stat,anova_p = f_oneway(batch_rmse[0],batch_rmse[1],batch_rmse[2],batch_rmse[3])\n",
        "          print('f_oneway:',test_stat,anova_p)\n",
        "\n",
        "        # 紀錄該參數的anova result\n",
        "        anova_data['batch size'].iloc[num] = np.round(anova_p,3)\n",
        "\n",
        "        # 紀錄該參數的最佳參數\n",
        "        best_parameter['batch size'].iloc[num] = best_para\n",
        "\n",
        "        # 紀錄每個參數之平均rmse\n",
        "        batch_result = [np.mean(batch_rmse[0]),np.mean(batch_rmse[1]),np.mean(batch_rmse[2]),np.mean(batch_rmse[3])]\n",
        "\n",
        "########################################################################################################################################\n",
        "\n",
        "    elif param_name == 'iterations':\n",
        "        iter_rmse = []\n",
        "        best_rmse,best_para = 100,1000\n",
        "        min_normality_p = 1000\n",
        "        for para in parameter:\n",
        "            parm_set_2 = SPCA_TWRotF_kfold(tree=100, depth=30, max_sample=0.7, batch_size=5, iteration=para ,seed = 47)\n",
        "            print(para,normal_test(parm_set_2),parm_set_2)\n",
        "\n",
        "            # 找出最好的參數\n",
        "            if np.mean(parm_set_2) < best_rmse:\n",
        "              best_para = para\n",
        "              best_rmse = np.mean(parm_set_2)\n",
        "            iter_rmse.append(parm_set_2)\n",
        "\n",
        "            # 紀錄每個參數的常態檢定p-value\n",
        "            iteration_data[str(para)].iloc[num] = normal_test(parm_set_2)\n",
        "\n",
        "            if normal_test(parm_set_2) < min_normality_p:\n",
        "              min_normality_p = normal_test(parm_set_2)\n",
        "              \n",
        "        if min_normality_p < 0.05 :\n",
        "          test_stat,anova_p = kruskal(iter_rmse[0],iter_rmse[1],iter_rmse[2],iter_rmse[3])\n",
        "          print('kruskal_oneway:',test_stat,anova_p)              \n",
        "        else:\n",
        "          test_stat,anova_p = f_oneway(iter_rmse[0],iter_rmse[1],iter_rmse[2],iter_rmse[3])\n",
        "          print('f_oneway:',test_stat,anova_p)\n",
        "  \n",
        "        # 紀錄該參數的anova result\n",
        "        anova_data['iteration'].iloc[num] = np.round(anova_p,3)\n",
        "\n",
        "        # 紀錄該參數的最佳參數\n",
        "        best_parameter['iteration'].iloc[num] = best_para\n",
        "\n",
        "        # 紀錄每個參數之平均rmse\n",
        "        iter_result = [np.mean(iter_rmse[0]),np.mean(iter_rmse[1]),np.mean(iter_rmse[2]),np.mean(iter_rmse[3])]\n",
        "\n",
        "print(tree_result)\n",
        "print(bootstrap_result)\n",
        "print(depth_result)\n",
        "print(batch_result)\n",
        "print(iter_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "random state =  47 : ================ iteration ================\n",
            "100 0.042 [0.01162198898805917, 0.01191550406946266, 0.011519893027761758, 0.011411575321668086, 0.011637321436554358, 0.010798128852089996, 0.011953012948457017, 0.011542336511248497, 0.011599241044184385, 0.01153195037323755]\n",
            "300 0.231 [0.011332838273688655, 0.011759090245353945, 0.011274231920924789, 0.011247333940802835, 0.011484662248621417, 0.011154091163074418, 0.011899305644576736, 0.011351407406793705, 0.011082977405697192, 0.011374791250465687]\n",
            "500 0.162 [0.011507733663972567, 0.011368413495875201, 0.011458777802412645, 0.01119737026017333, 0.01137516724694388, 0.010928217073694005, 0.011410535640960022, 0.011406782242710146, 0.01128906939957313, 0.011182728190300941]\n",
            "700 0.056 [0.011323220034012827, 0.011800347469896987, 0.011325741684483795, 0.011183612793048157, 0.011088559948887841, 0.01108910789156686, 0.011529982455467795, 0.01135083792299096, 0.01112751353329435, 0.011110366060071286]\n",
            "kruskal_oneway: 9.425853658536596 0.024133377142674935\n",
            "[0.011553095257272349, 0.011396072949999937, 0.011312479501661588, 0.011292928979372086]\n"
          ]
        }
      ],
      "source": [
        "num = 2\n",
        "\n",
        "for i in range(20):\n",
        "    print('random state = ',47,': ================ iteration ================')\n",
        "    iter_rmse = []\n",
        "    best_rmse,best_para = 100,1000\n",
        "    min_normality_p = 1000\n",
        "    for para in [100,300,500,700]:\n",
        "        parm_set_2 =  SPCA_TWRotF_kfold(tree=50, depth=None, max_sample=0.7, batch_size=5, iteration=para ,seed = 47)\n",
        "        print(para,normal_test(parm_set_2),parm_set_2)\n",
        "\n",
        "        # 找出最好的參數\n",
        "        if np.mean(parm_set_2) < best_rmse:\n",
        "            best_para = para\n",
        "            best_rmse = np.mean(parm_set_2)\n",
        "        iter_rmse.append(parm_set_2)\n",
        "\n",
        "        # 紀錄每個參數的常態檢定p-value\n",
        "        iteration_data[str(para)].iloc[num] = normal_test(parm_set_2)\n",
        "\n",
        "        if normal_test(parm_set_2) < min_normality_p:\n",
        "            min_normality_p = normal_test(parm_set_2) \n",
        "        \n",
        "    if min_normality_p < 0.05 :\n",
        "        test_stat,anova_p = kruskal(iter_rmse[0],iter_rmse[1],iter_rmse[2],iter_rmse[3])\n",
        "        print('kruskal_oneway:',test_stat,anova_p)\n",
        "    else:\n",
        "        test_stat,anova_p = f_oneway(iter_rmse[0],iter_rmse[1],iter_rmse[2],iter_rmse[3])\n",
        "        print('f_oneway:',test_stat,anova_p)\n",
        "\n",
        "    if anova_p <= 0.05:\n",
        "        anova_data['iteration'].iloc[num] = np.round(anova_p,3)\n",
        "        best_parameter['iteration'].iloc[num] = best_para   # 紀錄該參數的最佳參數\n",
        "        iter_result = [np.mean(iter_rmse[0]),np.mean(iter_rmse[1]),np.mean(iter_rmse[2]),np.mean(iter_rmse[3])]\n",
        "        print(iter_result)\n",
        "        break"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SPCA-SRotF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Strength_Rotation_Forest_SPCA(X , Y, test_x, max_depth, size, n_trees, k,batch,iter):\n",
        "    strength_set = []\n",
        "    Prediction_set = []\n",
        "    r_matrices , models = [],[]\n",
        "    for tree in range(n_trees):\n",
        "        feature_index = list(range(X.shape[1]))\n",
        "        k_subset = get_random_subset(feature_index,k) #每個子集有k個特徵，每個子集特徵不重複 #將訓練集中的屬性拆分為大小相等的 K 個非重疊子集。\n",
        "        rotation_matrix = np.zeros((X.shape[1],X.shape[1]),dtype=float) #591*591大小的矩陣\n",
        "        X_train, X_valid, y_train, y_valid = train_test_split(X, Y, train_size = size)\n",
        "\n",
        "        for each_subset in k_subset:\n",
        "            pca = MiniBatchSparsePCA(batch_size = batch ,n_iter = iter )\n",
        "            x_train,_,_,_ = train_test_split(X_train, y_train, train_size = 0.75)\n",
        "            X_subset = x_train.iloc[:,each_subset]\n",
        "            pca.fit(X_subset)\n",
        "            for i in range(0,len(pca.components_)):\n",
        "                for j in range(0,len(pca.components_)):\n",
        "                    rotation_matrix[ each_subset[i],each_subset[j] ] = pca.components_[i,j]\n",
        "\n",
        "        x_transformed = X_train.dot(rotation_matrix)\n",
        "        model = DecisionTreeRegressor(max_depth = max_depth).fit(x_transformed,y_train)\n",
        "\n",
        "        x_valid_transformed = X_valid.dot(rotation_matrix)\n",
        "        valid_prediction = model.predict(x_valid_transformed)\n",
        "\n",
        "        models.append(model) #存放每個樹的模型\n",
        "        r_matrices.append(rotation_matrix) #存放每個樹的旋轉矩陣\n",
        "\n",
        "        confidence = []\n",
        "        margin = np.abs(valid_prediction - y_valid)\n",
        "        for j in range(len(margin)):\n",
        "          confidence.append(1/ math.exp(margin.values[j]))\n",
        "        strength = np.sum(confidence)/len(confidence)\n",
        "        strength_set.append(strength)\n",
        "    \n",
        "    predicted_ys = [] #測試階段預測\n",
        "    for i,model in enumerate(models): \n",
        "        x_mod =  test_x.dot(r_matrices[i])  \n",
        "        predicted_y = model.predict(x_mod)\n",
        "        predicted_ys.append(predicted_y)\n",
        "    \n",
        "    final_result = []\n",
        "    for i in range(len(predicted_ys[0])):\n",
        "      predict_result = [] #存放每棵樹的預測值 #100棵樹有100個預測值\n",
        "      for j in range(len(predicted_ys)):\n",
        "        predict_result.append( (predicted_ys[j][i]) )\n",
        "      strength_predict_result = np.array(predict_result) * np.array(strength_set) #每顆樹的預測值*每個樹的strength\n",
        "      final_result.append( np.mean(strength_predict_result)  ) #存放最後的2000個預測值\n",
        "\n",
        "    return final_result\n",
        "\n",
        "def SPCA_SRotF_kfold(tree, depth, max_sample, batch_size, iteration,seed):\n",
        "    RMSE_set_spca_srotf = []\n",
        "    # split()  method generate indices to split data intSo training and test set.\n",
        "    kf = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "    for train_index, valid_index in kf.split(scaled_x, data_y):\n",
        "        # print('fold',cnt)\n",
        "        train_x = scaled_x.iloc[train_index, :]\n",
        "        train_y = data.iloc[train_index, :]['stab']\n",
        "        valid_x = scaled_x.iloc[valid_index, :]\n",
        "        valid_y = data.iloc[valid_index, :]['stab']\n",
        "\n",
        "        TWRotF_pred = Strength_Rotation_Forest_SPCA(X=train_x, Y=train_y, test_x=valid_x, max_depth=depth, size=max_sample,\n",
        "                                                  n_trees=tree, k=3, batch=batch_size, iter=iteration)\n",
        "\n",
        "        RMSE_set_spca_srotf.append(np.sqrt(mean_squared_error(valid_y, TWRotF_pred)))\n",
        "\n",
        "    mean_rmse = np.mean(RMSE_set_spca_srotf)\n",
        "    return RMSE_set_spca_srotf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================ trees ================\n",
            "100 0.674 [0.01164559911947431, 0.011721644215957314, 0.011488529421885524, 0.011497863616513402, 0.011556902836328242, 0.011045499697625376, 0.012020788614432643, 0.011794691835829901, 0.011585472736810137, 0.01143552821094244]\n",
            "300 0.275 [0.011574336876995895, 0.01154729480343087, 0.011496072200161097, 0.011244824685724481, 0.011498566938590324, 0.010957026851396769, 0.011680425593319528, 0.011681613703916639, 0.011264361095076425, 0.011223418004640074]\n",
            "500 0.365 [0.011590782585491557, 0.011620524317368793, 0.011446187980524823, 0.011278781907467792, 0.011425421750300417, 0.01092507994442745, 0.011698832292960105, 0.011616337244897171, 0.011253581813123324, 0.011317098477347489]\n",
            "700 0.757 [0.011602959552305923, 0.011482844813323026, 0.011494688204622456, 0.01130837997782688, 0.011400231893887263, 0.010970747421972748, 0.011705543504106606, 0.011641944916425305, 0.01132372061381926, 0.011232533133378299]\n",
            "f_oneway: 1.1844039150284198 0.3293220474288289\n",
            "================ sampling_sizes ================\n",
            "0.5 0.887 [0.012205364669575251, 0.011979702383269803, 0.011952250423750789, 0.011758034164282779, 0.011930592946493514, 0.011496938971384013, 0.012239922307004407, 0.012049225603415268, 0.011846738115539232, 0.011633288259259307]\n",
            "0.7 0.418 [0.011604719163575259, 0.011637555301453932, 0.011691286721955763, 0.011422286877912583, 0.011755767326793759, 0.011038432882786033, 0.011854488835352586, 0.01161492765043584, 0.011406379427813737, 0.011163001103685847]\n",
            "0.9 0.01 [0.011380608806856804, 0.0115638433666931, 0.011561512209649714, 0.011358008511648154, 0.011398235294313929, 0.010593349963545237, 0.011717180315904845, 0.01154583186466433, 0.011272330795594115, 0.011330263156292883]\n",
            "kruskal_oneway: 14.758709677419347 0.0006240033389612806\n",
            "================ depths ================\n",
            "10 0.993 [0.012965580379151371, 0.012759249941503747, 0.012517255848938477, 0.012365571532211331, 0.012398828155104432, 0.012083823384662799, 0.012529255168793729, 0.012743816908525616, 0.012640358351697438, 0.012222029897563606]\n",
            "20 0.471 [0.011744304612703637, 0.011461863429812322, 0.011572971249670968, 0.011444626024595688, 0.011397489960210259, 0.010911640706497035, 0.01184198074114318, 0.01183031952514996, 0.011553311084011588, 0.011260297699613833]\n",
            "30 0.279 [0.011795498627739551, 0.01187176675946466, 0.01157389394187562, 0.011492459679735105, 0.011420047067613546, 0.01115512218879192, 0.011810516005950948, 0.011897583260107815, 0.011473671939778782, 0.011180911407405958]\n",
            "40 0.951 [0.011875166326828482, 0.011690982941378329, 0.011569399042140759, 0.011342003219715357, 0.011503831459432184, 0.011160514277224228, 0.011668921136138447, 0.011647879609096117, 0.011398440586109344, 0.011263774428938377]\n",
            "50 0.61 [0.011812788920450422, 0.011561513991697888, 0.011580132862081677, 0.011442873764616671, 0.011598032896381104, 0.011152497049740041, 0.011857163247934798, 0.011710063051795595, 0.011464496908458667, 0.011534348940627489]\n",
            "F_onewayResult(statistic=31.076752611306805, pvalue=1.975254371519521e-12)\n",
            "================ batch ================\n",
            "3 0.49 [0.01175703237145766, 0.011662723372406711, 0.01163021430794685, 0.01139118771675401, 0.011497137173590223, 0.011179731170309898, 0.011638679475647808, 0.011755942460210613, 0.011420349215787445, 0.011297852484778928]\n",
            "5 0.493 [0.011917690673947707, 0.011766589480372933, 0.011387490513905875, 0.011485047873921987, 0.011545202962971606, 0.010960350518461514, 0.011676191065954055, 0.011757333895167237, 0.011408148418302516, 0.011492540991728506]\n",
            "7 0.06 [0.011768629925488355, 0.011741967068093231, 0.011627978708565695, 0.01135704009400482, 0.011583191251138008, 0.011191158776625099, 0.011814216898175084, 0.011689813985406137, 0.01119533039663977, 0.011183338919516683]\n",
            "9 0.654 [0.011811229683364143, 0.011933251331844716, 0.011687169106967295, 0.011413932296833275, 0.01141704878614242, 0.010994710534292719, 0.011896503416060638, 0.011607463342463282, 0.011431630753676534, 0.011311880423164325]\n",
            "f_oneway: 0.03862426780091909 0.9896867123293462\n",
            "================ iterations  ================\n",
            "[0.01157925203057993, 0.011416794075325209, 0.011417262831390893, 0.011416359403166775]\n",
            "[0.011909205784397437, 0.011518884529176533, 0.01137211642851631]\n",
            "[0.012522576956815254, 0.011501880503340845, 0.011567147087846391, 0.011512091302700162, 0.011571391163378436]\n",
            "[0.011523084974889014, 0.011539658639473394, 0.011515266602365288, 0.011550481967480934]\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'iter_result' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 181\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[39mprint\u001b[39m(depth_result)\n\u001b[0;32m    180\u001b[0m \u001b[39mprint\u001b[39m(batch_result)\n\u001b[1;32m--> 181\u001b[0m \u001b[39mprint\u001b[39m(iter_result)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'iter_result' is not defined"
          ]
        }
      ],
      "source": [
        "num = 5\n",
        "\n",
        "for param_name, parameter in spca_rotf_paremater_set.items():\n",
        "    print('================',param_name,'================')\n",
        "    if param_name == 'trees':\n",
        "        tree_rmse  = []\n",
        "        best_rmse,best_para = 100,1000\n",
        "        min_normality_p = 100\n",
        "        for para in parameter:\n",
        "            parm_set_2 = SPCA_SRotF_kfold(tree=para, depth=30, max_sample=0.7, batch_size=5, iteration=100,seed = 47 ) #23 31 47 52\n",
        "            print(para,normal_test(parm_set_2),parm_set_2)\n",
        "\n",
        "            # 找出最好的樹參數\n",
        "            if np.mean(parm_set_2) < best_rmse:\n",
        "              best_tree = para\n",
        "              best_rmse = np.mean(parm_set_2)\n",
        "            tree_rmse.append(parm_set_2)\n",
        "            \n",
        "            # 紀錄每個參數的常態檢定p-value\n",
        "            tree_data[str(para)].iloc[num] = normal_test(parm_set_2)\n",
        "\n",
        "            if normal_test(parm_set_2) < min_normality_p:\n",
        "              min_normality_p = normal_test(parm_set_2)\n",
        "\n",
        "        if min_normality_p < 0.05 :\n",
        "          test_stat,anova_p = kruskal(tree_rmse[0],tree_rmse[1],tree_rmse[2],tree_rmse[3])\n",
        "          print('kruskal_oneway:',test_stat,anova_p)              \n",
        "        else:\n",
        "          test_stat,anova_p = f_oneway(tree_rmse[0],tree_rmse[1],tree_rmse[2],tree_rmse[3])\n",
        "          print('f_oneway:',test_stat,anova_p)\n",
        "\n",
        "        anova_data['trees'].iloc[num] = np.round(anova_p,3)    # 紀錄該參數的anova result\n",
        "        best_parameter['trees'].iloc[num] = best_tree   # 紀錄該參數的最佳參數\n",
        "        tree_result = [np.mean(tree_rmse[0]),np.mean(tree_rmse[1]),np.mean(tree_rmse[2]),np.mean(tree_rmse[3])]   # 紀錄每個參數之平均rmse\n",
        "\n",
        "########################################################################################################################################\n",
        "\n",
        "    elif param_name == 'sampling_sizes':\n",
        "        sample_rmse = []\n",
        "        best_rmse,best_para = 100,1000\n",
        "        min_normality_p = 100\n",
        "        for para in parameter:\n",
        "            parm_set_2 = SPCA_SRotF_kfold(tree=100, depth=30, max_sample=para, batch_size=5, iteration=100,seed = 47 )\n",
        "            print(para,normal_test(parm_set_2),parm_set_2)\n",
        "\n",
        "            # 找出最好的參數\n",
        "            if np.mean(parm_set_2) < best_rmse:\n",
        "              best_para = para\n",
        "              best_rmse = np.mean(parm_set_2)\n",
        "            sample_rmse.append(parm_set_2)\n",
        "\n",
        "            # 紀錄每個參數的常態檢定p-value\n",
        "            bootstrap_size_data[str(para)].iloc[num] = normal_test(parm_set_2)\n",
        "\n",
        "            if normal_test(parm_set_2) < min_normality_p:\n",
        "              min_normality_p = normal_test(parm_set_2)\n",
        "              \n",
        "        if min_normality_p < 0.05 :\n",
        "          test_stat,anova_p = kruskal(sample_rmse[0],sample_rmse[1],sample_rmse[2])\n",
        "          print('kruskal_oneway:',test_stat,anova_p)              \n",
        "        else:\n",
        "          test_stat,anova_p = f_oneway(sample_rmse[0],sample_rmse[1],sample_rmse[2])\n",
        "          print('f_oneway:',test_stat,anova_p)\n",
        "\n",
        "        anova_data['bootstrap size'].iloc[num] = np.round(anova_p,3)\n",
        "\n",
        "        best_parameter['bootstrap size'].iloc[num] = best_para   # 紀錄該參數的最佳參數\n",
        "        bootstrap_result = [np.mean(sample_rmse[0]),np.mean(sample_rmse[1]),np.mean(sample_rmse[2])]  # 紀錄每個參數之平均rmse\n",
        "\n",
        "########################################################################################################################################\n",
        "\n",
        "    elif param_name == 'depths':\n",
        "        depth_rmse = []\n",
        "        best_rmse,best_para = 100,1000\n",
        "        for para in parameter:\n",
        "            parm_set_2 = SPCA_SRotF_kfold(tree=100, depth=para, max_sample=0.7, batch_size=5, iteration=100,seed = 47)\n",
        "            print(para,normal_test(parm_set_2),parm_set_2)\n",
        "\n",
        "            # 找出最好的參數\n",
        "            if np.mean(parm_set_2) < best_rmse:\n",
        "              best_para = para\n",
        "              best_rmse = np.mean(parm_set_2)\n",
        "            depth_rmse.append(parm_set_2)\n",
        "\n",
        "            # 紀錄每個參數的常態檢定p-value\n",
        "            depth_data[str(para)].iloc[num] = normal_test(parm_set_2)\n",
        "\n",
        "        print(f_oneway(depth_rmse[0],depth_rmse[1],depth_rmse[2],depth_rmse[3],depth_rmse[4]))\n",
        "\n",
        "        # 紀錄該參數的anova result\n",
        "        test_stat,anova_p = f_oneway(depth_rmse[0],depth_rmse[1],depth_rmse[2],depth_rmse[3],depth_rmse[4])\n",
        "        anova_data['max depth'].iloc[num] = np.round(anova_p,3)\n",
        "\n",
        "        # 紀錄該參數的最佳參數\n",
        "        best_parameter['max depth'].iloc[num] = best_para\n",
        "\n",
        "        # 紀錄每個參數之平均rmse\n",
        "        depth_result = [np.mean(depth_rmse[0]),np.mean(depth_rmse[1]),np.mean(depth_rmse[2]),np.mean(depth_rmse[3]),np.mean(depth_rmse[4])]\n",
        "\n",
        "########################################################################################################################################\n",
        "\n",
        "    elif param_name == 'batch':\n",
        "        batch_rmse = []\n",
        "        best_rmse,best_para = 100,1000\n",
        "        min_normality_p = 100\n",
        "\n",
        "        for para in parameter:\n",
        "            parm_set_2 = SPCA_SRotF_kfold(tree=100, depth=30, max_sample=0.7, batch_size=para, iteration=100,seed = 47)\n",
        "            print(para,normal_test(parm_set_2),parm_set_2)\n",
        "\n",
        "            # 找出最好的參數\n",
        "            if np.mean(parm_set_2) < best_rmse:\n",
        "              best_para = para\n",
        "              best_rmse = np.mean(parm_set_2)\n",
        "            batch_rmse.append(parm_set_2)\n",
        "\n",
        "            # 紀錄每個參數的常態檢定p-value\n",
        "            batch_data[str(para)].iloc[num] = normal_test(parm_set_2)\n",
        "\n",
        "            if normal_test(parm_set_2) < min_normality_p:\n",
        "              min_normality_p = normal_test(parm_set_2)\n",
        "              \n",
        "        if min_normality_p < 0.05 :\n",
        "          test_stat,anova_p = kruskal(batch_rmse[0],batch_rmse[1],batch_rmse[2],batch_rmse[3])\n",
        "          print('kruskal_oneway:',test_stat,anova_p)              \n",
        "        else:\n",
        "          test_stat,anova_p = f_oneway(batch_rmse[0],batch_rmse[1],batch_rmse[2],batch_rmse[3])\n",
        "          print('f_oneway:',test_stat,anova_p)\n",
        "\n",
        "        # 紀錄該參數的anova result\n",
        "        anova_data['batch size'].iloc[num] = np.round(anova_p,3)\n",
        "\n",
        "        # 紀錄該參數的最佳參數\n",
        "        best_parameter['batch size'].iloc[num] = best_para\n",
        "\n",
        "        # 紀錄每個參數之平均rmse\n",
        "        batch_result = [np.mean(batch_rmse[0]),np.mean(batch_rmse[1]),np.mean(batch_rmse[2]),np.mean(batch_rmse[3])]\n",
        "\n",
        "########################################################################################################################################\n",
        "\n",
        "    elif param_name == 'iterations':\n",
        "        iter_rmse = []\n",
        "        best_rmse,best_para = 100,1000\n",
        "        min_normality_p = 1000\n",
        "        for para in parameter:\n",
        "            parm_set_2 = SPCA_SRotF_kfold(tree=100, depth=30, max_sample=0.7, batch_size=5, iteration=para ,seed = 47)\n",
        "            print(para,normal_test(parm_set_2),parm_set_2)\n",
        "\n",
        "            # 找出最好的參數\n",
        "            if np.mean(parm_set_2) < best_rmse:\n",
        "              best_para = para\n",
        "              best_rmse = np.mean(parm_set_2)\n",
        "            iter_rmse.append(parm_set_2)\n",
        "\n",
        "            # 紀錄每個參數的常態檢定p-value\n",
        "            iteration_data[str(para)].iloc[num] = normal_test(parm_set_2)\n",
        "\n",
        "            if normal_test(parm_set_2) < min_normality_p:\n",
        "              min_normality_p = normal_test(parm_set_2)\n",
        "              \n",
        "        if min_normality_p < 0.05 :\n",
        "          test_stat,anova_p = kruskal(iter_rmse[0],iter_rmse[1],iter_rmse[2],iter_rmse[3])\n",
        "          print('kruskal_oneway:',test_stat,anova_p)              \n",
        "        else:\n",
        "          test_stat,anova_p = f_oneway(iter_rmse[0],iter_rmse[1],iter_rmse[2],iter_rmse[3])\n",
        "          print('f_oneway:',test_stat,anova_p)\n",
        "  \n",
        "        # 紀錄該參數的anova result\n",
        "        anova_data['iteration'].iloc[num] = np.round(anova_p,3)\n",
        "\n",
        "        # 紀錄該參數的最佳參數\n",
        "        best_parameter['iteration'].iloc[num] = best_para\n",
        "\n",
        "        # 紀錄每個參數之平均rmse\n",
        "        iter_result = [np.mean(iter_rmse[0]),np.mean(iter_rmse[1]),np.mean(iter_rmse[2]),np.mean(iter_rmse[3])]\n",
        "\n",
        "print(tree_result)\n",
        "print(bootstrap_result)\n",
        "print(depth_result)\n",
        "print(batch_result)\n",
        "print(iter_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num = 2\n",
        "for param_name, parameter in spca_rotf_paremater_set.items():\n",
        "    if param_name == 'iterations ':\n",
        "        print('================ iteration ================')\n",
        "        iter_rmse = []\n",
        "        best_rmse,best_para = 100,1000\n",
        "        min_normality_p = 1000\n",
        "        for para in parameter:\n",
        "            parm_set_2 =  SPCA_SRotF_kfold(tree=100, depth=30, max_sample=0.7, batch_size=5, iteration=para ,seed = 47)\n",
        "            print(para,normal_test(parm_set_2),parm_set_2)\n",
        "\n",
        "            # 找出最好的參數\n",
        "            if np.mean(parm_set_2) < best_rmse:\n",
        "              best_para = para\n",
        "              best_rmse = np.mean(parm_set_2)\n",
        "            iter_rmse.append(parm_set_2)\n",
        "\n",
        "            # 紀錄每個參數的常態檢定p-value\n",
        "            iteration_data[str(para)].iloc[num] = normal_test(parm_set_2)\n",
        "\n",
        "            if normal_test(parm_set_2) < min_normality_p:\n",
        "              min_normality_p = normal_test(parm_set_2)\n",
        "              \n",
        "        if min_normality_p < 0.05 :\n",
        "          test_stat,anova_p = kruskal(iter_rmse[0],iter_rmse[1],iter_rmse[2],iter_rmse[3])\n",
        "          print('kruskal_oneway:',test_stat,anova_p)              \n",
        "        else:\n",
        "          test_stat,anova_p = f_oneway(iter_rmse[0],iter_rmse[1],iter_rmse[2],iter_rmse[3])\n",
        "          print('f_oneway:',test_stat,anova_p)\n",
        "  \n",
        "        # 紀錄該參數的anova result\n",
        "        anova_data['iteration'].iloc[num] = np.round(anova_p,3)\n",
        "\n",
        "        # 紀錄該參數的最佳參數\n",
        "        best_parameter['iteration'].iloc[num] = best_para\n",
        "\n",
        "        # 紀錄每個參數之平均rmse\n",
        "        iter_result = [np.mean(iter_rmse[0]),np.mean(iter_rmse[1]),np.mean(iter_rmse[2]),np.mean(iter_rmse[3])]\n",
        "\n",
        "print(iter_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "depth_data.to_csv(\"depth.csv\",index=False)\n",
        "tree_data.to_csv(\"tree.csv\",index=False)\n",
        "bootstrap_size_data.to_csv(\"bootstrap size.csv\",index=False)\n",
        "batch_data.to_csv(\"batch size.csv\",index=False)\n",
        "iteration_data.to_csv(\"iteration.csv\",index=False)\n",
        "\n",
        "best_parameter.to_csv(\"bast parameter.csv\",index=False)\n",
        "anova_data.to_csv(\"anova result.csv\",index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
