{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XaDLqVcOJZwZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.stats import shapiro,f_oneway,kruskal\n",
        "\n",
        "data = pd.read_csv(\"Electrical Grid.csv\")\n",
        "\n",
        "data_x = data.drop(['stab','stabf'],axis=1)\n",
        "data_y = data['stab']\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaled_x = scaler.fit_transform(data_x)\n",
        "scaled_x = pd.DataFrame(scaled_x, columns=data_x.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tJ_yjZ5xKCG2"
      },
      "outputs": [],
      "source": [
        "depth_data = pd.read_csv(\"depth.csv\")\n",
        "tree_data = pd.read_csv(\"tree.csv\")\n",
        "max_feature_data = pd.read_csv(\"max feature.csv\")\n",
        "bootstrap_size_data = pd.read_csv(\"bootstrap size.csv\")\n",
        "batch_data = pd.read_csv(\"batch size.csv\")\n",
        "iteration_data = pd.read_csv(\"iteration.csv\")\n",
        "\n",
        "best_parameter = pd.read_csv(\"bast parameter.csv\")\n",
        "anova_data = pd.read_csv(\"anova result.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lXmMT6YsJ9Sy"
      },
      "outputs": [],
      "source": [
        "def normal_test(data):\n",
        "    test_stat,p_value = shapiro(data)\n",
        "    return np.round(p_value,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AzDJ1rtbKBj0"
      },
      "outputs": [],
      "source": [
        "rotf_paremater_set = {\"trees\":[100,300,500,700],\"sampling_sizes\":[0.5,0.7,0.9],'depths':[10,20,30,40,50]}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RotF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zCD4wA-kNJiy"
      },
      "outputs": [],
      "source": [
        "def get_random_subset(iterable,k):\n",
        "    subsets = []\n",
        "    iteration = 0\n",
        "    np.random.shuffle(iterable)\n",
        "    subset = 0\n",
        "    limit = len(iterable)/k\n",
        "    while iteration < limit:\n",
        "        if k <= len(iterable):\n",
        "            subset = k\n",
        "        else:\n",
        "            subset = len(iterable)\n",
        "        subsets.append(iterable[-subset:])\n",
        "        del iterable[-subset:]\n",
        "        iteration+=1\n",
        "    return subsets\n",
        "\n",
        "def Rotation_Forest(X , Y, test_x, max_depth, size, n_trees, k):\n",
        "  r_matrices , models = [],[]\n",
        "\n",
        "  for tree in range(n_trees):\n",
        "    feature_index = list(range(X.shape[1]))\n",
        "    k_subset = get_random_subset(feature_index,k) #每個子集有k個特徵，每個子集特徵不重複 #將訓練集中的屬性拆分為大小相等的 K 個非重疊子集。\n",
        "    rotation_matrix = np.zeros((X.shape[1],X.shape[1]),dtype=float) #591*591大小的矩陣\n",
        "    \n",
        "    for each_subset in k_subset:\n",
        "      pca = PCA()\n",
        "      X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=size)\n",
        "      X_subset = X_train.iloc[:,each_subset]\n",
        "      pca.fit(X_subset)\n",
        "      for i in range(0,len(pca.components_)):\n",
        "        for j in range(0,len(pca.components_)):\n",
        "          rotation_matrix[each_subset[i],each_subset[j]] = pca.components_[i,j]\n",
        "\n",
        "    x_transformed = X.dot(rotation_matrix)\n",
        "    model = DecisionTreeRegressor(max_depth = max_depth)\n",
        "    model.fit(x_transformed,Y)\n",
        "    models.append(model) #存放每個樹的模型\n",
        "    r_matrices.append(rotation_matrix) #存放每個樹的旋轉矩陣\n",
        "\n",
        "  return models,r_matrices\n",
        "\n",
        "def model_predict(models,r_matrices,x):\n",
        "    predicted_ys = []\n",
        "    for i,model in enumerate(models):\n",
        "        x_mod =  x.dot(r_matrices[i])  \n",
        "        predicted_y = model.predict(x_mod)\n",
        "        predicted_ys.append(predicted_y)\n",
        "        \n",
        "    final_results = []\n",
        "    for i in range(len(predicted_ys[0])): #總共要預測的Y有幾個 #2000個預測值\n",
        "        predict_result = [] #存放每棵樹的預測值 #100棵樹有100個預測值\n",
        "        for j in range(len(predicted_ys)): #每棵樹的預測值 #100棵樹\n",
        "            predict_result.append( (predicted_ys[j][i]) )\n",
        "        final_results.append(np.mean(predict_result))\n",
        "\n",
        "    return final_results\n",
        "\n",
        "def RotF_kfold(tree,depth,max_sample,seed):\n",
        "    RMSE_set_rotf = []\n",
        "    kf = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "    for train_index, valid_index in kf.split(scaled_x, data_y): # split()  method generate indices to split data intSo training and test set.\n",
        "        #print('fold',cnt)\n",
        "        train_x = scaled_x.iloc[train_index,:]\n",
        "        train_y = data.iloc[train_index,:]['stab']\n",
        "        valid_x = scaled_x.iloc[valid_index,:]\n",
        "        valid_y = data.iloc[valid_index,:]['stab']\n",
        "        models,r_matrices = Rotation_Forest(X=train_x,Y=train_y,test_x=valid_x, max_depth= depth, size= max_sample, n_trees=tree, k =3 )\n",
        "        rot_pred = model_predict(models,r_matrices,valid_x)\n",
        "        RMSE_set_rotf.append( np.sqrt( mean_squared_error(valid_y,rot_pred)))\n",
        "\n",
        "    mean_rmse = np.mean(RMSE_set_rotf)\n",
        "    return RMSE_set_rotf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================ trees ================\n",
            "100 0.689 [0.011987311248332732, 0.011994282619423263, 0.012156725625959028, 0.011741502520151673, 0.011802461165136769, 0.011290746936678092, 0.012265751589777264, 0.01221038428796153, 0.0118329477529619, 0.011606115711842988]\n",
            "300 0.522 [0.011790129811796238, 0.011879722998698933, 0.011791229222268525, 0.011585420298305242, 0.011720585062500908, 0.011152059870397657, 0.012130149457771888, 0.01210696968114149, 0.011791788658921783, 0.01147863066979329]\n",
            "500 0.449 [0.011844433450245558, 0.011901014538889731, 0.011762945102513061, 0.011605731212221145, 0.011690586440036968, 0.01100501485885767, 0.012175693041185579, 0.012062931350984228, 0.011699406362178082, 0.01151764711023444]\n",
            "700 0.809 [0.01181246107052202, 0.011878597762751008, 0.011771811131557501, 0.011507374292432546, 0.01175684651615985, 0.01109771748342525, 0.012135258348796073, 0.01199898043812453, 0.011581845693150353, 0.01148579264447762]\n",
            "f_oneway: 0.7723198627800278 0.517110938389744\n",
            "================ sampling_sizes ================\n",
            "0.5 0.572 [0.011739174604965565, 0.011730435892332145, 0.01172862745473705, 0.01154652538327906, 0.011555321510313991, 0.011089897658441365, 0.012012474263151725, 0.011890159831889588, 0.011617010578418276, 0.011459649363242655]\n",
            "0.7 0.557 [0.011800247176507319, 0.011906221371949284, 0.011789178931945228, 0.011674412287970046, 0.011708916501845957, 0.011237693273111696, 0.012195061890799703, 0.011979756835724779, 0.01173244616620931, 0.011635303304264447]\n",
            "0.9 0.95 [0.011992383836592967, 0.011952355521901886, 0.011979469406803818, 0.011719053705595228, 0.011825898354190222, 0.011340713781696155, 0.012269154494520533, 0.01215817794950135, 0.011761912375252813, 0.011626158049030175]\n",
            "f_oneway: 1.9320410430409456 0.16435782441157906\n",
            "================ depths ================\n",
            "10 0.66 [0.013293771675490125, 0.013206616517030208, 0.013236056460229786, 0.012896450066223742, 0.013255192890349531, 0.012406824072000602, 0.013422048225937823, 0.013602785841355054, 0.012999613530884132, 0.01282875879844667]\n",
            "20 0.909 [0.011900120958471445, 0.011853965997944893, 0.01184112786859011, 0.011623812631766333, 0.011718217955396862, 0.011168642448996643, 0.012225363521667795, 0.012131077329971509, 0.011613529946316902, 0.01150712733139157]\n",
            "30 0.99 [0.011713405093707519, 0.011839016520933474, 0.011886227838783256, 0.011499609318516357, 0.01172605178499731, 0.011124362169948672, 0.012205599279404898, 0.012013920172630073, 0.011664799297552519, 0.0114069551443224]\n",
            "40 0.96 [0.011792919772390578, 0.01187704129957239, 0.011961404253607921, 0.011492968564839955, 0.011728995262750515, 0.011177425823877454, 0.012195322609322252, 0.012034982686853948, 0.01154783857857064, 0.011536899346747606]\n",
            "50 0.942 [0.01187702001385121, 0.01191904954912265, 0.011791239393196408, 0.011610925225794898, 0.011610223861329146, 0.011193150284073453, 0.012166903168124537, 0.012024557606731212, 0.011603104266329775, 0.011436985780520114]\n",
            "F_onewayResult(statistic=39.737738481025886, pvalue=3.16926359033167e-14)\n",
            "[0.011888822945822523, 0.011742668573159596, 0.011726540346734647, 0.011702668538139675]\n",
            "[0.011636927654077143, 0.011765923774032776, 0.011862527747508515]\n",
            "[0.013114811807794769, 0.011758298599051404, 0.011707994662079647, 0.011734579819853326, 0.01172331591490734]\n"
          ]
        }
      ],
      "source": [
        "num = 1\n",
        "\n",
        "for param_name, parameter in rotf_paremater_set.items():\n",
        "    print('================',param_name,'================')\n",
        "    if param_name == 'trees':\n",
        "        tree_rmse  = []\n",
        "        best_rmse,best_para = 100,1000\n",
        "        min_normality_p = 100\n",
        "        for para in parameter:\n",
        "            parm_set_2 = RotF_kfold(tree=para,depth=None,max_sample=0.7,seed = 47 ) #23 31 47 52\n",
        "            print(para,normal_test(parm_set_2),parm_set_2)\n",
        "\n",
        "            # 找出最好的樹參數\n",
        "            if np.mean(parm_set_2) < best_rmse:\n",
        "              best_tree = para\n",
        "              best_rmse = np.mean(parm_set_2)\n",
        "            tree_rmse.append(parm_set_2)\n",
        "            \n",
        "            # 紀錄每個參數的常態檢定p-value\n",
        "            tree_data[str(para)].iloc[num] = normal_test(parm_set_2)\n",
        "\n",
        "            if normal_test(parm_set_2) < min_normality_p:\n",
        "              min_normality_p = normal_test(parm_set_2)\n",
        "\n",
        "        if min_normality_p < 0.05 :\n",
        "          test_stat,anova_p = kruskal(tree_rmse[0],tree_rmse[1],tree_rmse[2],tree_rmse[3])\n",
        "          print('kruskal_oneway:',test_stat,anova_p)              \n",
        "        else:\n",
        "          test_stat,anova_p = f_oneway(tree_rmse[0],tree_rmse[1],tree_rmse[2],tree_rmse[3])\n",
        "          print('f_oneway:',test_stat,anova_p)\n",
        "\n",
        "        anova_data['trees'].iloc[num] = np.round(anova_p,3)    # 紀錄該參數的anova result\n",
        "        best_parameter['trees'].iloc[num] = best_tree   # 紀錄該參數的最佳參數\n",
        "        tree_result = [np.mean(tree_rmse[0]),np.mean(tree_rmse[1]),np.mean(tree_rmse[2]),np.mean(tree_rmse[3])]   # 紀錄每個參數之平均rmse\n",
        "\n",
        "########################################################################################################################################\n",
        "\n",
        "    elif param_name == 'sampling_sizes':\n",
        "        sample_rmse = []\n",
        "        best_rmse,best_para = 100,1000\n",
        "        min_normality_p = 100\n",
        "        for para in parameter:\n",
        "            parm_set_2 = RotF_kfold(tree=300,depth=20,max_sample=para,seed = 47)\n",
        "            print(para,normal_test(parm_set_2),parm_set_2)\n",
        "\n",
        "            # 找出最好的參數\n",
        "            if np.mean(parm_set_2) < best_rmse:\n",
        "              best_para = para\n",
        "              best_rmse = np.mean(parm_set_2)\n",
        "            sample_rmse.append(parm_set_2)\n",
        "\n",
        "            # 紀錄每個參數的常態檢定p-value\n",
        "            bootstrap_size_data[str(para)].iloc[num] = normal_test(parm_set_2)\n",
        "\n",
        "            if normal_test(parm_set_2) < min_normality_p:\n",
        "              min_normality_p = normal_test(parm_set_2)\n",
        "              \n",
        "        if min_normality_p < 0.05 :\n",
        "          test_stat,anova_p = kruskal(sample_rmse[0],sample_rmse[1],sample_rmse[2])\n",
        "          print('kruskal_oneway:',test_stat,anova_p)              \n",
        "        else:\n",
        "          test_stat,anova_p = f_oneway(sample_rmse[0],sample_rmse[1],sample_rmse[2])\n",
        "          print('f_oneway:',test_stat,anova_p)\n",
        "\n",
        "        anova_data['bootstrap size'].iloc[num] = np.round(anova_p,3)\n",
        "\n",
        "        best_parameter['bootstrap size'].iloc[num] = best_para   # 紀錄該參數的最佳參數\n",
        "        bootstrap_result = [np.mean(sample_rmse[0]),np.mean(sample_rmse[1]),np.mean(sample_rmse[2])]  # 紀錄每個參數之平均rmse\n",
        "\n",
        "########################################################################################################################################\n",
        "\n",
        "    elif param_name == 'depths':\n",
        "        depth_rmse = []\n",
        "        best_rmse,best_para = 100,1000\n",
        "        for para in parameter:\n",
        "            parm_set_2 = RotF_kfold(tree=300,depth=para,max_sample=0.7,seed = 47)\n",
        "            print(para,normal_test(parm_set_2),parm_set_2)\n",
        "\n",
        "            # 找出最好的參數\n",
        "            if np.mean(parm_set_2) < best_rmse:\n",
        "              best_para = para\n",
        "              best_rmse = np.mean(parm_set_2)\n",
        "            depth_rmse.append(parm_set_2)\n",
        "\n",
        "            # 紀錄每個參數的常態檢定p-value\n",
        "            depth_data[str(para)].iloc[num] = normal_test(parm_set_2)\n",
        "\n",
        "        print(f_oneway(depth_rmse[0],depth_rmse[1],depth_rmse[2],depth_rmse[3],depth_rmse[4]))\n",
        "\n",
        "        # 紀錄該參數的anova result\n",
        "        test_stat,anova_p = f_oneway(depth_rmse[0],depth_rmse[1],depth_rmse[2],depth_rmse[3],depth_rmse[4])\n",
        "        anova_data['max depth'].iloc[num] = np.round(anova_p,3)\n",
        "\n",
        "        # 紀錄該參數的最佳參數\n",
        "        best_parameter['max depth'].iloc[num] = best_para\n",
        "\n",
        "        # 紀錄每個參數之平均rmse\n",
        "        depth_result = [np.mean(depth_rmse[0]),np.mean(depth_rmse[1]),np.mean(depth_rmse[2]),np.mean(depth_rmse[3]),np.mean(depth_rmse[4])]\n",
        "        \n",
        "print(tree_result)\n",
        "print(bootstrap_result)\n",
        "print(depth_result)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TWRotF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def weighted_average(prediction_set,oobrmse):\n",
        "    final_results = []\n",
        "    for i in range(len(prediction_set[0])): #總共要預測的Y有幾個 #2000個預測值\n",
        "        predict_result = [] #存放每棵樹的預測值 #100棵樹有100個預測值\n",
        "        final_result = 0\n",
        "        for j in range(len(prediction_set)): #每棵樹的預測值 #100棵樹\n",
        "            predict_result.append( (prediction_set[j][i]) )\n",
        "\n",
        "        for k in range(len(predict_result)): #加權預測值\n",
        "            final_result =  final_result + predict_result[k] * oobrmse[k]\n",
        "        final_results.append(final_result)\n",
        "    return final_results\n",
        "\n",
        "def Tree_Weighting_Rotation_Forest(X , Y, test_x, max_depth, size, n_trees, k):\n",
        "    strength_set = []\n",
        "    Prediction_set = []\n",
        "    OOB_MSE = []\n",
        "    r_matrices , models = [],[]\n",
        "    for tree in range(n_trees):\n",
        "        feature_index = list(range(X.shape[1]))\n",
        "        k_subset = get_random_subset(feature_index,k) #每個子集有k個特徵，每個子集特徵不重複 #將訓練集中的屬性拆分為大小相等的 K 個非重疊子集。\n",
        "        rotation_matrix = np.zeros((X.shape[1],X.shape[1]),dtype=float) #591*591大小的矩陣\n",
        "        X_train, X_valid, y_train, y_valid = train_test_split(X, Y, train_size = size)\n",
        "\n",
        "        for each_subset in k_subset:\n",
        "            pca = PCA()\n",
        "            x_train,_,_,_ = train_test_split(X_train, y_train, train_size = 0.7)\n",
        "            X_subset = x_train.iloc[:,each_subset]\n",
        "            pca.fit(X_subset)\n",
        "            for i in range(0,len(pca.components_)):\n",
        "                for j in range(0,len(pca.components_)):\n",
        "                    rotation_matrix[ each_subset[i],each_subset[j] ] = pca.components_[i,j]\n",
        "\n",
        "        x_transformed = X_train.dot(rotation_matrix)\n",
        "        model = DecisionTreeRegressor(max_depth = max_depth).fit(x_transformed,y_train)\n",
        "\n",
        "        x_valid_transformed = X_valid.dot(rotation_matrix)\n",
        "        valid_prediction = model.predict(x_valid_transformed)\n",
        "\n",
        "        models.append(model) #存放每個樹的模型\n",
        "        r_matrices.append(rotation_matrix) #存放每個樹的旋轉矩陣\n",
        "\n",
        "        OOB_MSE.append(mean_squared_error(y_valid,valid_prediction) )\n",
        "        \n",
        "    oob_mse_prop = OOB_MSE/np.sum(OOB_MSE)\n",
        "    \n",
        "    predicted_ys = [] #測試階段預測\n",
        "    for i,model in enumerate(models): \n",
        "        x_mod =  test_x.dot(r_matrices[i])  \n",
        "        predicted_y = model.predict(x_mod)\n",
        "        predicted_ys.append(predicted_y)\n",
        "\n",
        "    weighted_result = weighted_average(predicted_ys,oob_mse_prop)\n",
        "    return weighted_result\n",
        "\n",
        "def TWRotF_kfold(tree,depth,max_sample,seed):\n",
        "    RMSE_set_twrotf = []\n",
        "    kf = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "    for train_index, valid_index in kf.split(scaled_x, data_y): # split()  method generate indices to split data intSo training and test set.\n",
        "        #print('fold',cnt)\n",
        "        train_x = scaled_x.iloc[train_index,:]\n",
        "        train_y = data.iloc[train_index,:]['stab']\n",
        "        valid_x = scaled_x.iloc[valid_index,:]\n",
        "        valid_y = data.iloc[valid_index,:]['stab']\n",
        "        TWRotF_pred = Tree_Weighting_Rotation_Forest(X=train_x,Y=train_y,test_x=valid_x, max_depth= depth, size= max_sample, n_trees=tree, k =3 )\n",
        "        RMSE_set_twrotf.append( np.sqrt( mean_squared_error(valid_y,TWRotF_pred)))\n",
        "\n",
        "    mean_rmse = np.mean(RMSE_set_twrotf)\n",
        "    return RMSE_set_twrotf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================ trees ================\n",
            "100 0.722 [0.01274842327668985, 0.01245300873637978, 0.01237178823108606, 0.012278316821634458, 0.012314440066182875, 0.011804550530478597, 0.012737580177606714, 0.0128233151131707, 0.012188568253804061, 0.01203662807516986]\n",
            "300 0.954 [0.012476672063913317, 0.012314374258830717, 0.012359000162953365, 0.011942074029665595, 0.012161392338562359, 0.011664732622128908, 0.012690788950087224, 0.012513426823061564, 0.012134316302049232, 0.011870465316904704]\n",
            "500 0.895 [0.012337093847375311, 0.012369026792481017, 0.012384812407393272, 0.012040163173408096, 0.012189967442361883, 0.011640540999445913, 0.012648125405935686, 0.012559175678011007, 0.012088467129180557, 0.011861593074169676]\n",
            "700 0.845 [0.012327273710538406, 0.01229307864497304, 0.012233705177152584, 0.012117024270366395, 0.012201711706010634, 0.011614434491118285, 0.012664704575175338, 0.01257028063958359, 0.012100300528311105, 0.01187650672620669]\n",
            "f_oneway: 0.703864943673035 0.5559642710439059\n",
            "================ sampling_sizes ================\n",
            "0.5 0.987 [0.012953754293490272, 0.012763927370247565, 0.01280908604543168, 0.012520702129860796, 0.012746648461002869, 0.012211704372246179, 0.013190921196011831, 0.01288963742853004, 0.01267436197857239, 0.012451560345242372]\n",
            "0.7 0.309 [0.01237916728462503, 0.012386928880292278, 0.012368936059993238, 0.012127400129167363, 0.012355435826666131, 0.011726521485998322, 0.012688444830538416, 0.012595023181319779, 0.01232967284904139, 0.011899684925448044]\n",
            "0.9 0.919 [0.011974731318475365, 0.012046741355799685, 0.012030041321164515, 0.011763393769947414, 0.011926329073475121, 0.011436485819984252, 0.012439683916324228, 0.012239717459538951, 0.011891923058849825, 0.01176701274882741]\n",
            "f_oneway: 18.779495592399442 7.744526829444992e-06\n",
            "================ depths ================\n",
            "10 0.136 [0.013626984862940322, 0.01336058718845652, 0.013536013002736465, 0.013277001152381965, 0.013393087855989739, 0.012874404697455094, 0.013643569524922846, 0.0136860775233681, 0.013335464390374991, 0.01289469569371554]\n",
            "20 0.176 [0.01230705416098458, 0.012360425397592007, 0.012267114748106041, 0.012241449144695209, 0.012253083114305277, 0.0115697158633854, 0.012697361226779414, 0.012508271528764743, 0.012283034772286762, 0.011886440814192649]\n",
            "30 0.505 [0.012408897214312004, 0.012288127688894465, 0.012432127465161416, 0.012154490034425789, 0.012228245735793926, 0.011653875783579019, 0.01261059334658759, 0.012611162186366546, 0.012215892933309432, 0.01195201746988062]\n",
            "40 0.923 [0.012351892144079316, 0.01232325193873528, 0.012288315195843523, 0.012123429749803611, 0.012197138578486616, 0.011710466833912999, 0.012732176588177414, 0.012569040798278473, 0.012261512214428715, 0.011969035681535017]\n",
            "50 0.853 [0.01243451568169121, 0.012293204185284184, 0.012319594791120924, 0.01210083331035035, 0.012198974918978726, 0.011690031481558576, 0.012632218651797221, 0.012560238892700448, 0.012211494916246712, 0.01189819572497746]\n",
            "F_onewayResult(statistic=28.950431768102717, pvalue=6.185225656278711e-12)\n",
            "[0.012375661928220295, 0.012212724286815697, 0.012211896594976242, 0.012199902046943606]\n",
            "[0.012721230362063598, 0.012285721545309, 0.011951605984238677]\n",
            "[0.013362788589234157, 0.01223739507710921, 0.012255542985831081, 0.012252625972328096, 0.012233930255470583]\n"
          ]
        }
      ],
      "source": [
        "num = 7\n",
        "\n",
        "for param_name, parameter in rotf_paremater_set.items():\n",
        "    print('================',param_name,'================')\n",
        "    if param_name == 'trees':\n",
        "        tree_rmse  = []\n",
        "        best_rmse,best_para = 100,1000\n",
        "        min_normality_p = 100\n",
        "        for para in parameter:\n",
        "            parm_set_2 = TWRotF_kfold(tree=para,depth=None,max_sample=0.7,seed = 47 ) #23 31 47 52\n",
        "            print(para,normal_test(parm_set_2),parm_set_2)\n",
        "\n",
        "            # 找出最好的樹參數\n",
        "            if np.mean(parm_set_2) < best_rmse:\n",
        "              best_tree = para\n",
        "              best_rmse = np.mean(parm_set_2)\n",
        "            tree_rmse.append(parm_set_2)\n",
        "            \n",
        "            # 紀錄每個參數的常態檢定p-value\n",
        "            tree_data[str(para)].iloc[num] = normal_test(parm_set_2)\n",
        "\n",
        "            if normal_test(parm_set_2) < min_normality_p:\n",
        "              min_normality_p = normal_test(parm_set_2)\n",
        "\n",
        "        if min_normality_p < 0.05 :\n",
        "          test_stat,anova_p = kruskal(tree_rmse[0],tree_rmse[1],tree_rmse[2],tree_rmse[3])\n",
        "          print('kruskal_oneway:',test_stat,anova_p)              \n",
        "        else:\n",
        "          test_stat,anova_p = f_oneway(tree_rmse[0],tree_rmse[1],tree_rmse[2],tree_rmse[3])\n",
        "          print('f_oneway:',test_stat,anova_p)\n",
        "\n",
        "        anova_data['trees'].iloc[num] = np.round(anova_p,3)    # 紀錄該參數的anova result\n",
        "        best_parameter['trees'].iloc[num] = best_tree   # 紀錄該參數的最佳參數\n",
        "        tree_result = [np.mean(tree_rmse[0]),np.mean(tree_rmse[1]),np.mean(tree_rmse[2]),np.mean(tree_rmse[3])]   # 紀錄每個參數之平均rmse\n",
        "\n",
        "########################################################################################################################################\n",
        "\n",
        "    elif param_name == 'sampling_sizes':\n",
        "        sample_rmse = []\n",
        "        best_rmse,best_para = 100,1000\n",
        "        min_normality_p = 100\n",
        "        for para in parameter:\n",
        "            parm_set_2 = TWRotF_kfold(tree=300,depth=20,max_sample=para,seed = 47)\n",
        "            print(para,normal_test(parm_set_2),parm_set_2)\n",
        "\n",
        "            # 找出最好的參數\n",
        "            if np.mean(parm_set_2) < best_rmse:\n",
        "              best_para = para\n",
        "              best_rmse = np.mean(parm_set_2)\n",
        "            sample_rmse.append(parm_set_2)\n",
        "\n",
        "            # 紀錄每個參數的常態檢定p-value\n",
        "            bootstrap_size_data[str(para)].iloc[num] = normal_test(parm_set_2)\n",
        "\n",
        "            if normal_test(parm_set_2) < min_normality_p:\n",
        "              min_normality_p = normal_test(parm_set_2)\n",
        "              \n",
        "        if min_normality_p < 0.05 :\n",
        "          test_stat,anova_p = kruskal(sample_rmse[0],sample_rmse[1],sample_rmse[2])\n",
        "          print('kruskal_oneway:',test_stat,anova_p)              \n",
        "        else:\n",
        "          test_stat,anova_p = f_oneway(sample_rmse[0],sample_rmse[1],sample_rmse[2])\n",
        "          print('f_oneway:',test_stat,anova_p)\n",
        "\n",
        "        anova_data['bootstrap size'].iloc[num] = np.round(anova_p,3)\n",
        "\n",
        "        best_parameter['bootstrap size'].iloc[num] = best_para   # 紀錄該參數的最佳參數\n",
        "        bootstrap_result = [np.mean(sample_rmse[0]),np.mean(sample_rmse[1]),np.mean(sample_rmse[2])]  # 紀錄每個參數之平均rmse\n",
        "\n",
        "########################################################################################################################################\n",
        "\n",
        "    elif param_name == 'depths':\n",
        "        depth_rmse = []\n",
        "        best_rmse,best_para = 100,1000\n",
        "        for para in parameter:\n",
        "            parm_set_2 = TWRotF_kfold(tree=300,depth=para,max_sample=0.7,seed = 47)\n",
        "            print(para,normal_test(parm_set_2),parm_set_2)\n",
        "\n",
        "            # 找出最好的參數\n",
        "            if np.mean(parm_set_2) < best_rmse:\n",
        "              best_para = para\n",
        "              best_rmse = np.mean(parm_set_2)\n",
        "            depth_rmse.append(parm_set_2)\n",
        "\n",
        "            # 紀錄每個參數的常態檢定p-value\n",
        "            depth_data[str(para)].iloc[num] = normal_test(parm_set_2)\n",
        "\n",
        "        print(f_oneway(depth_rmse[0],depth_rmse[1],depth_rmse[2],depth_rmse[3],depth_rmse[4]))\n",
        "\n",
        "        # 紀錄該參數的anova result\n",
        "        test_stat,anova_p = f_oneway(depth_rmse[0],depth_rmse[1],depth_rmse[2],depth_rmse[3],depth_rmse[4])\n",
        "        anova_data['max depth'].iloc[num] = np.round(anova_p,3)\n",
        "\n",
        "        # 紀錄該參數的最佳參數\n",
        "        best_parameter['max depth'].iloc[num] = best_para\n",
        "\n",
        "        # 紀錄每個參數之平均rmse\n",
        "        depth_result = [np.mean(depth_rmse[0]),np.mean(depth_rmse[1]),np.mean(depth_rmse[2]),np.mean(depth_rmse[3]),np.mean(depth_rmse[4])]\n",
        "        \n",
        "print(tree_result)\n",
        "print(bootstrap_result)\n",
        "print(depth_result)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SRotF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Strength_Rotation_Forest(X , Y, test_x, max_depth, size, n_trees, k):\n",
        "    strength_set = []\n",
        "    Prediction_set = []\n",
        "    r_matrices , models = [],[]\n",
        "    for tree in range(n_trees):\n",
        "        feature_index = list(range(X.shape[1]))\n",
        "        k_subset = get_random_subset(feature_index,k) #每個子集有k個特徵，每個子集特徵不重複 #將訓練集中的屬性拆分為大小相等的 K 個非重疊子集。\n",
        "        rotation_matrix = np.zeros((X.shape[1],X.shape[1]),dtype=float) #591*591大小的矩陣\n",
        "        X_train, X_valid, y_train, y_valid = train_test_split(X, Y, train_size = size)\n",
        "\n",
        "        for each_subset in k_subset:\n",
        "            pca = PCA()\n",
        "            x_train,_,_,_ = train_test_split(X_train, y_train, train_size = 0.7)\n",
        "            X_subset = x_train.iloc[:,each_subset]\n",
        "            pca.fit(X_subset)\n",
        "            for i in range(0,len(pca.components_)):\n",
        "                for j in range(0,len(pca.components_)):\n",
        "                    rotation_matrix[ each_subset[i],each_subset[j] ] = pca.components_[i,j]\n",
        "\n",
        "        x_transformed = X_train.dot(rotation_matrix)\n",
        "        model = DecisionTreeRegressor(max_depth = max_depth).fit(x_transformed,y_train)\n",
        "\n",
        "        x_valid_transformed = X_valid.dot(rotation_matrix)\n",
        "        valid_prediction = model.predict(x_valid_transformed)\n",
        "\n",
        "        models.append(model) #存放每個樹的模型\n",
        "        r_matrices.append(rotation_matrix) #存放每個樹的旋轉矩陣\n",
        "\n",
        "        confidence = []\n",
        "        margin = np.abs(valid_prediction - y_valid)\n",
        "        for j in range(len(margin)):\n",
        "          confidence.append(1/ math.exp(margin.values[j]))\n",
        "        strength = np.sum(confidence)/len(confidence)\n",
        "        strength_set.append(strength)\n",
        "    \n",
        "    predicted_ys = [] #測試階段預測\n",
        "    for i,model in enumerate(models): \n",
        "        x_mod =  test_x.dot(r_matrices[i])  \n",
        "        predicted_y = model.predict(x_mod)\n",
        "        predicted_ys.append(predicted_y)\n",
        "    \n",
        "    final_result = []\n",
        "    for i in range(len(predicted_ys[0])):\n",
        "      predict_result = [] #存放每棵樹的預測值 #100棵樹有100個預測值\n",
        "      for j in range(len(predicted_ys)):\n",
        "        predict_result.append( (predicted_ys[j][i]) )\n",
        "      strength_predict_result = np.array(predict_result) * np.array(strength_set) #每顆樹的預測值*每個樹的strength\n",
        "      final_result.append( np.mean(strength_predict_result)  ) #存放最後的2000個預測值\n",
        "\n",
        "    return final_result\n",
        "\n",
        "def SRotF_kfold(tree,depth,max_sample,seed):\n",
        "    RMSE_set_srotf = []\n",
        "    kf = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "    for train_index, valid_index in kf.split(scaled_x, data_y): # split()  method generate indices to split data intSo training and test set.\n",
        "        #print('fold',cnt)\n",
        "        train_x = scaled_x.iloc[train_index,:]\n",
        "        train_y = data.iloc[train_index,:]['stab']\n",
        "        valid_x = scaled_x.iloc[valid_index,:]\n",
        "        valid_y = data.iloc[valid_index,:]['stab']\n",
        "        SRotF_pred = Strength_Rotation_Forest(X=train_x,Y=train_y,test_x=valid_x, max_depth= depth, size= max_sample, n_trees=tree, k =3 )\n",
        "        RMSE_set_srotf.append( np.sqrt( mean_squared_error(valid_y,SRotF_pred)))\n",
        "\n",
        "    mean_rmse = np.mean(RMSE_set_srotf)\n",
        "    return RMSE_set_srotf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================ trees ================\n",
            "100 0.135 [0.012910882451065938, 0.012749531661373431, 0.012602152156850628, 0.012594489803874507, 0.012752207739501455, 0.012013136066066795, 0.012946373683579728, 0.01285554125756261, 0.012632033123593641, 0.01225512713592549]\n",
            "300 0.987 [0.012638772249958196, 0.012537010194047567, 0.012575923023320447, 0.012368537188935965, 0.012491168541601122, 0.011952905163644565, 0.012916317553755403, 0.012714505550306697, 0.012254712260330586, 0.012232288375531829]\n",
            "500 0.635 [0.012568886991237819, 0.012523828966075824, 0.012564503297561477, 0.012302539234926751, 0.012491728907457186, 0.011900699075902082, 0.01295057585466183, 0.012792085005767112, 0.012459055846012911, 0.012026258810674414]\n",
            "700 0.936 [0.012515575288255885, 0.012576428710340046, 0.012529319820194838, 0.012293866358180054, 0.012384162634664712, 0.011933946350771692, 0.01287314671889609, 0.012707334078303848, 0.012437914972545578, 0.012083016666835112]\n",
            "f_oneway: 0.9529533137208577 0.4253887105471654\n",
            "================ sampling_sizes ================\n",
            "0.5 0.692 [0.013113199663131755, 0.012953709681365543, 0.012936295379040313, 0.012823857278767298, 0.01297847356215985, 0.012388229500120852, 0.013359377250688222, 0.013382307013459525, 0.012884924550575995, 0.012689849287848437]\n",
            "0.7 0.463 [0.012730346731851161, 0.012624951912485145, 0.012538379320332693, 0.012335725322393847, 0.012472522263779602, 0.011949245594078178, 0.012913045546764125, 0.012803407364708962, 0.012593079331677873, 0.012026138202327084]\n",
            "0.9 0.915 [0.012377820336303628, 0.012322259454825816, 0.012344065269353749, 0.012042467212674827, 0.012173322072087973, 0.011635506435920265, 0.01266792635246363, 0.012489023916250959, 0.012187329487363363, 0.011867217417072562]\n",
            "f_oneway: 15.00330024218313 4.153568557643287e-05\n",
            "================ depths ================\n",
            "10 0.56 [0.013873609133966429, 0.013664203512276608, 0.013573963387650196, 0.013428802374640378, 0.013501207509351054, 0.012900610037274446, 0.01397200247928037, 0.013982978572019448, 0.013572898865091639, 0.013204455824718702]\n",
            "20 0.817 [0.012649647438044842, 0.012425144641809683, 0.012544149615029173, 0.012412336683237863, 0.012457256695843228, 0.011886530993453978, 0.013014733437703204, 0.012896547829873508, 0.012380235842155347, 0.012200909128243871]\n",
            "30 0.188 [0.012618199738010887, 0.01261712161373935, 0.012599856490254017, 0.012198425313910839, 0.012552227269727005, 0.01185345853432139, 0.012837262765160123, 0.012711273120845606, 0.012503642497373839, 0.012145447414518886]\n",
            "40 0.789 [0.01269849515476947, 0.01250297506291348, 0.012535441452644618, 0.01227743531810591, 0.01249744348186773, 0.011983245904504738, 0.012851222712423276, 0.012811362747012002, 0.012442643161729406, 0.012167334342614534]\n",
            "50 0.857 [0.012677203418278127, 0.012486187394335666, 0.012508430414870942, 0.012356274631572906, 0.012437501865191325, 0.011958794356734293, 0.012919658040120574, 0.012964514821310696, 0.01229580065271006, 0.0121901012789779]\n",
            "F_onewayResult(statistic=24.565928344645926, pvalue=7.941885485286053e-11)\n",
            "[0.012631147507939422, 0.012468214010143239, 0.012458016199027741, 0.012433471159898787]\n",
            "[0.01295102231671578, 0.012498684159039866, 0.012210693795431677]\n",
            "[0.013567473169626929, 0.01248674923053947, 0.012463691475786194, 0.012476759933858517, 0.012479446687410248]\n"
          ]
        }
      ],
      "source": [
        "num = 4\n",
        "\n",
        "for param_name, parameter in rotf_paremater_set.items():\n",
        "    print('================',param_name,'================')\n",
        "    if param_name == 'trees':\n",
        "        tree_rmse  = []\n",
        "        best_rmse,best_para = 100,1000\n",
        "        min_normality_p = 100\n",
        "        for para in parameter:\n",
        "            parm_set_2 = SRotF_kfold(tree=para,depth=None,max_sample=0.7,seed = 47 ) #23 31 47 52\n",
        "            print(para,normal_test(parm_set_2),parm_set_2)\n",
        "\n",
        "            # 找出最好的樹參數\n",
        "            if np.mean(parm_set_2) < best_rmse:\n",
        "              best_tree = para\n",
        "              best_rmse = np.mean(parm_set_2)\n",
        "            tree_rmse.append(parm_set_2)\n",
        "            \n",
        "            # 紀錄每個參數的常態檢定p-value\n",
        "            tree_data[str(para)].iloc[num] = normal_test(parm_set_2)\n",
        "\n",
        "            if normal_test(parm_set_2) < min_normality_p:\n",
        "              min_normality_p = normal_test(parm_set_2)\n",
        "\n",
        "        if min_normality_p < 0.05 :\n",
        "          test_stat,anova_p = kruskal(tree_rmse[0],tree_rmse[1],tree_rmse[2],tree_rmse[3])\n",
        "          print('kruskal_oneway:',test_stat,anova_p)              \n",
        "        else:\n",
        "          test_stat,anova_p = f_oneway(tree_rmse[0],tree_rmse[1],tree_rmse[2],tree_rmse[3])\n",
        "          print('f_oneway:',test_stat,anova_p)\n",
        "\n",
        "        anova_data['trees'].iloc[num] = np.round(anova_p,3)    # 紀錄該參數的anova result\n",
        "        best_parameter['trees'].iloc[num] = best_tree   # 紀錄該參數的最佳參數\n",
        "        tree_result = [np.mean(tree_rmse[0]),np.mean(tree_rmse[1]),np.mean(tree_rmse[2]),np.mean(tree_rmse[3])]   # 紀錄每個參數之平均rmse\n",
        "\n",
        "########################################################################################################################################\n",
        "\n",
        "    elif param_name == 'sampling_sizes':\n",
        "        sample_rmse = []\n",
        "        best_rmse,best_para = 100,1000\n",
        "        min_normality_p = 100\n",
        "        for para in parameter:\n",
        "            parm_set_2 = SRotF_kfold(tree=300,depth=20,max_sample=para,seed = 47)\n",
        "            print(para,normal_test(parm_set_2),parm_set_2)\n",
        "\n",
        "            # 找出最好的參數\n",
        "            if np.mean(parm_set_2) < best_rmse:\n",
        "              best_para = para\n",
        "              best_rmse = np.mean(parm_set_2)\n",
        "            sample_rmse.append(parm_set_2)\n",
        "\n",
        "            # 紀錄每個參數的常態檢定p-value\n",
        "            bootstrap_size_data[str(para)].iloc[num] = normal_test(parm_set_2)\n",
        "\n",
        "            if normal_test(parm_set_2) < min_normality_p:\n",
        "              min_normality_p = normal_test(parm_set_2)\n",
        "              \n",
        "        if min_normality_p < 0.05 :\n",
        "          test_stat,anova_p = kruskal(sample_rmse[0],sample_rmse[1],sample_rmse[2])\n",
        "          print('kruskal_oneway:',test_stat,anova_p)              \n",
        "        else:\n",
        "          test_stat,anova_p = f_oneway(sample_rmse[0],sample_rmse[1],sample_rmse[2])\n",
        "          print('f_oneway:',test_stat,anova_p)\n",
        "\n",
        "        anova_data['bootstrap size'].iloc[num] = np.round(anova_p,3)\n",
        "\n",
        "        best_parameter['bootstrap size'].iloc[num] = best_para   # 紀錄該參數的最佳參數\n",
        "        bootstrap_result = [np.mean(sample_rmse[0]),np.mean(sample_rmse[1]),np.mean(sample_rmse[2])]  # 紀錄每個參數之平均rmse\n",
        "\n",
        "########################################################################################################################################\n",
        "\n",
        "    elif param_name == 'depths':\n",
        "        depth_rmse = []\n",
        "        best_rmse,best_para = 100,1000\n",
        "        for para in parameter:\n",
        "            parm_set_2 = SRotF_kfold(tree=300,depth=para,max_sample=0.7,seed = 47)\n",
        "            print(para,normal_test(parm_set_2),parm_set_2)\n",
        "\n",
        "            # 找出最好的參數\n",
        "            if np.mean(parm_set_2) < best_rmse:\n",
        "              best_para = para\n",
        "              best_rmse = np.mean(parm_set_2)\n",
        "            depth_rmse.append(parm_set_2)\n",
        "\n",
        "            # 紀錄每個參數的常態檢定p-value\n",
        "            depth_data[str(para)].iloc[num] = normal_test(parm_set_2)\n",
        "\n",
        "        print(f_oneway(depth_rmse[0],depth_rmse[1],depth_rmse[2],depth_rmse[3],depth_rmse[4]))\n",
        "\n",
        "        # 紀錄該參數的anova result\n",
        "        test_stat,anova_p = f_oneway(depth_rmse[0],depth_rmse[1],depth_rmse[2],depth_rmse[3],depth_rmse[4])\n",
        "        anova_data['max depth'].iloc[num] = np.round(anova_p,3)\n",
        "\n",
        "        # 紀錄該參數的最佳參數\n",
        "        best_parameter['max depth'].iloc[num] = best_para\n",
        "\n",
        "        # 紀錄每個參數之平均rmse\n",
        "        depth_result = [np.mean(depth_rmse[0]),np.mean(depth_rmse[1]),np.mean(depth_rmse[2]),np.mean(depth_rmse[3]),np.mean(depth_rmse[4])]\n",
        "        \n",
        "print(tree_result)\n",
        "print(bootstrap_result)\n",
        "print(depth_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "depth_data.to_csv(\"depth.csv\",index=False)\n",
        "tree_data.to_csv(\"tree.csv\",index=False)\n",
        "max_feature_data.to_csv(\"max feature.csv\",index=False)\n",
        "bootstrap_size_data.to_csv(\"bootstrap size.csv\",index=False)\n",
        "best_parameter.to_csv(\"bast parameter.csv\",index=False)\n",
        "anova_data.to_csv(\"anova result.csv\",index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
